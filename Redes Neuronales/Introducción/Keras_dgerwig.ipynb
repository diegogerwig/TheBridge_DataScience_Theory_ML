{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (71.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: keras in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (71.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"insatall\" - maybe you meant \"install\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from statsmodels) (1.26.4)\n",
      "Collecting scipy!=1.9.2,>=1.8 (from statsmodels)\n",
      "  Downloading scipy-1.14.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from statsmodels) (2.2.2)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.2-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.8 MB 6.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/9.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.6/9.8 MB 12.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.6/9.8 MB 12.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.7/9.8 MB 7.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.8 MB 6.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/9.8 MB 5.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.0/9.8 MB 5.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.2/9.8 MB 5.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/9.8 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.2/9.8 MB 6.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.8/9.8 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/9.8 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/9.8 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.9/9.8 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.9/9.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.8 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.0/9.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.1/9.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.2/9.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.3/9.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.8/9.8 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.4/9.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.0/9.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.0/9.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.0/9.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.1/9.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.1/9.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.2/9.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.3/9.8 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.4/9.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.9/9.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.5/9.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.0/9.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.8/9.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.9/9.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.0/9.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.3/9.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.6/9.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 233.9/233.9 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.0-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/44.5 MB 6.3 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.6/44.5 MB 6.1 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.9/44.5 MB 6.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.2/44.5 MB 6.4 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.5/44.5 MB 6.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.8/44.5 MB 6.3 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 2.1/44.5 MB 6.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/44.5 MB 6.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.7/44.5 MB 6.2 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 3.1/44.5 MB 6.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/44.5 MB 6.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.7/44.5 MB 6.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 4.0/44.5 MB 6.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 4.3/44.5 MB 6.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.6/44.5 MB 6.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.9/44.5 MB 6.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.3/44.5 MB 6.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 5.7/44.5 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.1/44.5 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.4/44.5 MB 6.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.7/44.5 MB 6.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 7.1/44.5 MB 6.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 7.4/44.5 MB 6.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 7.7/44.5 MB 6.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 8.1/44.5 MB 6.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 8.4/44.5 MB 6.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 8.4/44.5 MB 6.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 8.6/44.5 MB 6.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.9/44.5 MB 6.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 9.3/44.5 MB 6.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 9.6/44.5 MB 6.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 10.0/44.5 MB 6.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.3/44.5 MB 6.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.7/44.5 MB 6.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 11.0/44.5 MB 6.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 11.4/44.5 MB 6.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 11.8/44.5 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 12.1/44.5 MB 6.9 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 12.5/44.5 MB 7.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 12.8/44.5 MB 7.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 13.3/44.5 MB 7.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 13.6/44.5 MB 7.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 14.1/44.5 MB 7.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 14.3/44.5 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.8/44.5 MB 7.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 15.2/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 15.6/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 15.9/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.2/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.4/44.5 MB 7.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.7/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 16.9/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 17.2/44.5 MB 7.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 17.6/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 17.9/44.5 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 18.1/44.5 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 18.4/44.5 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 18.7/44.5 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.0/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.4/44.5 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.7/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.0/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.4/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.7/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 21.0/44.5 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 21.4/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 21.6/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 22.0/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 22.3/44.5 MB 7.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 22.7/44.5 MB 7.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.0/44.5 MB 7.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.3/44.5 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.7/44.5 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.0/44.5 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.4/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 24.6/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 25.0/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 25.4/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 25.5/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 25.9/44.5 MB 6.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 26.3/44.5 MB 6.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 26.6/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 26.9/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.3/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.6/44.5 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 27.9/44.5 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.1/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.5/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.7/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.0/44.5 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.3/44.5 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.6/44.5 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.9/44.5 MB 6.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.1/44.5 MB 6.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.4/44.5 MB 6.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.7/44.5 MB 6.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.0/44.5 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.3/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.6/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.9/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.3/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.9/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.2/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.4/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.8/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.1/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.5/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.8/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.1/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.5/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.8/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.2/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.5/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.9/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.2/44.5 MB 6.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.6/44.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 38.0/44.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.7/44.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.0/44.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.4/44.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.1/44.5 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.5/44.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.2/44.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.6/44.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.9/44.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.1/44.5 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.4/44.5 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.7/44.5 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.5 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.3/44.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.6/44.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.5 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.2/44.5 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.4/44.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.5 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 6.9 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy, patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 scipy-1.14.0 statsmodels-0.14.2\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\usuario\\onedrive\\code_dgerwig\\.venv\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "   ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.9 MB 2.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/10.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/10.9 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.4/10.9 MB 19.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.7/10.9 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.8/10.9 MB 29.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/10.9 MB 30.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.9/10.9 MB 36.4 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 301.8/301.8 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install setuptools\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip insatall seaborn\n",
    "!pip install sklearn\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 VersionNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "----------------------- -----------\n",
      "absl-py                 2.1.0\n",
      "asttokens               2.4.1\n",
      "astunparse              1.6.3\n",
      "certifi                 2024.7.4\n",
      "charset-normalizer      3.3.2\n",
      "colorama                0.4.6\n",
      "comm                    0.2.2\n",
      "contourpy               1.2.1\n",
      "cycler                  0.12.1\n",
      "debugpy                 1.8.2\n",
      "decorator               5.1.1\n",
      "executing               2.0.1\n",
      "flatbuffers             24.3.25\n",
      "fonttools               4.53.1\n",
      "gast                    0.6.0\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.64.1\n",
      "h5py                    3.11.0\n",
      "idna                    3.7\n",
      "ipykernel               6.29.5\n",
      "ipython                 8.26.0\n",
      "jedi                    0.19.1\n",
      "joblib                  1.4.2\n",
      "jupyter_client          8.6.2\n",
      "jupyter_core            5.7.2\n",
      "keras                   3.4.1\n",
      "kiwisolver              1.4.5\n",
      "libclang                18.1.1\n",
      "Markdown                3.6\n",
      "markdown-it-py          3.0.0\n",
      "MarkupSafe              2.1.5\n",
      "matplotlib              3.9.1\n",
      "matplotlib-inline       0.1.7\n",
      "mdurl                   0.1.2\n",
      "ml-dtypes               0.4.0\n",
      "namex                   0.0.8\n",
      "nest-asyncio            1.6.0\n",
      "numpy                   1.26.4\n",
      "opt-einsum              3.3.0\n",
      "optree                  0.12.1\n",
      "packaging               24.1\n",
      "pandas                  2.2.2\n",
      "parso                   0.8.4\n",
      "patsy                   0.5.6\n",
      "pillow                  10.4.0\n",
      "pip                     24.1.2\n",
      "platformdirs            4.2.2\n",
      "prompt_toolkit          3.0.47\n",
      "protobuf                4.25.3\n",
      "psutil                  6.0.0\n",
      "pure-eval               0.2.2\n",
      "Pygments                2.18.0\n",
      "pyparsing               3.1.2\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2024.1\n",
      "pywin32                 306\n",
      "pyzmq                   26.0.3\n",
      "requests                2.32.3\n",
      "rich                    13.7.1\n",
      "scikit-learn            1.5.1\n",
      "scipy                   1.14.0\n",
      "setuptools              71.0.1\n",
      "six                     1.16.0\n",
      "stack-data              0.6.3\n",
      "statsmodels             0.14.2\n",
      "tensorboard             2.17.0\n",
      "tensorboard-data-server 0.7.2\n",
      "tensorflow              2.17.0\n",
      "tensorflow-intel        2.17.0\n",
      "termcolor               2.4.0\n",
      "threadpoolctl           3.5.0\n",
      "tornado                 6.4.1\n",
      "traitlets               5.14.3\n",
      "typing_extensions       4.12.2\n",
      "tzdata                  2024.1\n",
      "urllib3                 2.2.2\n",
      "wcwidth                 0.2.13\n",
      "Werkzeug                3.0.3\n",
      "wheel                   0.43.0\n",
      "wrapt                   1.16.0\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "plt.imshow(X_train[0], cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\OneDrive\\code_dgerwig\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.2099822e-02, -3.2458447e-02,  1.7288998e-02, ...,\n",
       "         5.2649111e-02,  2.2665285e-02,  2.9394232e-02],\n",
       "       [-4.4560328e-02, -6.9872685e-02, -3.2671914e-03, ...,\n",
       "        -4.2445958e-05, -6.3857660e-02, -8.0431923e-03],\n",
       "       [ 4.1418813e-02, -1.2203082e-03,  2.6178464e-02, ...,\n",
       "        -6.3666463e-02,  6.9794253e-02, -4.2635594e-02],\n",
       "       ...,\n",
       "       [-1.4551371e-02,  4.2518348e-02,  4.3166116e-02, ...,\n",
       "         7.2285190e-02, -6.7465678e-02, -1.0219663e-02],\n",
       "       [-4.6263158e-02, -6.2124759e-02, -7.7141896e-03, ...,\n",
       "        -6.0391307e-02,  5.4980874e-02, -2.7204193e-02],\n",
       "       [ 1.0638833e-03,  6.0534790e-02,  1.1236630e-02, ...,\n",
       "        -5.3491019e-02,  2.5306404e-02,  4.1275010e-02]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5047 - loss: 1.7430 - val_accuracy: 0.8674 - val_loss: 0.5970\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8614 - loss: 0.5644 - val_accuracy: 0.8975 - val_loss: 0.3932\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.4117 - val_accuracy: 0.9100 - val_loss: 0.3309\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.3576 - val_accuracy: 0.9162 - val_loss: 0.2995\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.3192 - val_accuracy: 0.9205 - val_loss: 0.2790\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2921 - val_accuracy: 0.9242 - val_loss: 0.2643\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2845 - val_accuracy: 0.9296 - val_loss: 0.2509\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2704 - val_accuracy: 0.9302 - val_loss: 0.2421\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2544 - val_accuracy: 0.9322 - val_loss: 0.2334\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2483 - val_accuracy: 0.9372 - val_loss: 0.2238\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.2358 - val_accuracy: 0.9393 - val_loss: 0.2160\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.2177 - val_accuracy: 0.9408 - val_loss: 0.2105\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2141 - val_accuracy: 0.9436 - val_loss: 0.2032\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2077 - val_accuracy: 0.9446 - val_loss: 0.1978\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1978 - val_accuracy: 0.9471 - val_loss: 0.1924\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1947 - val_accuracy: 0.9483 - val_loss: 0.1897\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1903 - val_accuracy: 0.9502 - val_loss: 0.1838\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1833 - val_accuracy: 0.9511 - val_loss: 0.1789\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1772 - val_accuracy: 0.9526 - val_loss: 0.1738\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1740 - val_accuracy: 0.9534 - val_loss: 0.1707\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1671 - val_accuracy: 0.9544 - val_loss: 0.1664\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1636 - val_accuracy: 0.9543 - val_loss: 0.1636\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1547 - val_accuracy: 0.9560 - val_loss: 0.1604\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1484 - val_accuracy: 0.9562 - val_loss: 0.1563\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1543 - val_accuracy: 0.9580 - val_loss: 0.1533\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1494 - val_accuracy: 0.9581 - val_loss: 0.1516\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1411 - val_accuracy: 0.9598 - val_loss: 0.1473\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1401 - val_accuracy: 0.9601 - val_loss: 0.1457\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1356 - val_accuracy: 0.9603 - val_loss: 0.1435\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1330 - val_accuracy: 0.9611 - val_loss: 0.1402\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1265 - val_accuracy: 0.9626 - val_loss: 0.1378\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.1230 - val_accuracy: 0.9624 - val_loss: 0.1372\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.1236 - val_accuracy: 0.9628 - val_loss: 0.1339\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1208 - val_accuracy: 0.9637 - val_loss: 0.1322\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.1135 - val_accuracy: 0.9643 - val_loss: 0.1303\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1123 - val_accuracy: 0.9651 - val_loss: 0.1280\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1123 - val_accuracy: 0.9652 - val_loss: 0.1266\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.1083 - val_accuracy: 0.9656 - val_loss: 0.1248\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.1053 - val_accuracy: 0.9662 - val_loss: 0.1235\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.1016 - val_accuracy: 0.9670 - val_loss: 0.1212\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.1055 - val_accuracy: 0.9666 - val_loss: 0.1207\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1024 - val_accuracy: 0.9672 - val_loss: 0.1185\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.1024 - val_accuracy: 0.9672 - val_loss: 0.1196\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0964 - val_accuracy: 0.9682 - val_loss: 0.1162\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0942 - val_accuracy: 0.9685 - val_loss: 0.1141\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0958 - val_accuracy: 0.9689 - val_loss: 0.1134\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0915 - val_accuracy: 0.9688 - val_loss: 0.1122\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0899 - val_accuracy: 0.9692 - val_loss: 0.1108\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0907 - val_accuracy: 0.9703 - val_loss: 0.1099\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0819 - val_accuracy: 0.9700 - val_loss: 0.1084\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0859 - val_accuracy: 0.9685 - val_loss: 0.1099\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0797 - val_accuracy: 0.9705 - val_loss: 0.1057\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0788 - val_accuracy: 0.9703 - val_loss: 0.1054\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0740 - val_accuracy: 0.9712 - val_loss: 0.1027\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0729 - val_accuracy: 0.9724 - val_loss: 0.0998\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0717 - val_accuracy: 0.9725 - val_loss: 0.0983\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0701 - val_accuracy: 0.9726 - val_loss: 0.0987\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0656 - val_accuracy: 0.9725 - val_loss: 0.0967\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0631 - val_accuracy: 0.9731 - val_loss: 0.0966\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0606 - val_accuracy: 0.9728 - val_loss: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2070f47a8a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.6945800185203552, 0.8684999942779541, 0.8918200135231018, 0.9028199911117554, 0.9107800126075745, 0.9167199730873108, 0.9218599796295166, 0.9257599711418152, 0.9294599890708923, 0.9321600198745728, 0.9344199895858765, 0.9370200037956238, 0.9388800263404846, 0.9412199854850769, 0.9429000020027161, 0.945360004901886, 0.9465600252151489, 0.9479799866676331, 0.9495999813079834, 0.9514999985694885, 0.952239990234375, 0.953760027885437, 0.9552000164985657, 0.9562399983406067, 0.9574999809265137, 0.9582800269126892, 0.9597799777984619, 0.9609799981117249, 0.9616199731826782, 0.9626399874687195, 0.9637600183486938, 0.9647600054740906, 0.9654399752616882, 0.9666399955749512, 0.9672999978065491, 0.967739999294281, 0.9690600037574768, 0.9696800112724304, 0.9700599908828735, 0.9709200263023376, 0.9714199900627136, 0.9724599719047546, 0.9728400111198425, 0.9733399748802185, 0.9739199876785278, 0.9739999771118164, 0.9749600291252136, 0.9755799770355225, 0.9764999747276306, 0.9767400026321411], 'loss': [1.2584397792816162, 0.5160437226295471, 0.39521539211273193, 0.34472790360450745, 0.31485581398010254, 0.293353408575058, 0.2763301134109497, 0.2628348171710968, 0.2506573796272278, 0.2402171492576599, 0.23099656403064728, 0.22229896485805511, 0.2146027684211731, 0.2073110193014145, 0.2004627138376236, 0.19395066797733307, 0.18827152252197266, 0.18224455416202545, 0.17703834176063538, 0.17167718708515167, 0.16705311834812164, 0.16228224337100983, 0.1578843593597412, 0.15363405644893646, 0.14965282380580902, 0.14590393006801605, 0.14216426014900208, 0.1385604441165924, 0.13529743254184723, 0.13203191757202148, 0.1288105696439743, 0.12567877769470215, 0.1228688508272171, 0.12000974267721176, 0.11722682416439056, 0.11469216644763947, 0.11208339035511017, 0.10971610993146896, 0.10714930295944214, 0.10495086014270782, 0.10289493203163147, 0.10054659098386765, 0.09846752136945724, 0.09650889039039612, 0.09438853710889816, 0.0926533192396164, 0.09068030118942261, 0.08901044726371765, 0.08727600425481796, 0.08549806475639343], 'val_accuracy': [0.8673999905586243, 0.8974999785423279, 0.9100000262260437, 0.9161999821662903, 0.9204999804496765, 0.9241999983787537, 0.9296000003814697, 0.9301999807357788, 0.932200014591217, 0.9372000098228455, 0.939300000667572, 0.9408000111579895, 0.9435999989509583, 0.944599986076355, 0.9470999836921692, 0.9483000040054321, 0.9502000212669373, 0.9510999917984009, 0.9526000022888184, 0.9534000158309937, 0.9544000029563904, 0.9542999863624573, 0.9559999704360962, 0.9562000036239624, 0.9580000042915344, 0.9581000208854675, 0.9598000049591064, 0.960099995136261, 0.9603000283241272, 0.9610999822616577, 0.9625999927520752, 0.9624000191688538, 0.9628000259399414, 0.963699996471405, 0.9642999768257141, 0.9650999903678894, 0.9652000069618225, 0.9656000137329102, 0.9661999940872192, 0.9670000076293945, 0.9666000008583069, 0.967199981212616, 0.967199981212616, 0.9682000279426575, 0.968500018119812, 0.9689000248908997, 0.9688000082969666, 0.9692000150680542, 0.970300018787384, 0.9700000286102295], 'val_loss': [0.5969629883766174, 0.39324304461479187, 0.33085760474205017, 0.2994612455368042, 0.27902182936668396, 0.2642807960510254, 0.2509019672870636, 0.2420831024646759, 0.23341354727745056, 0.22381117939949036, 0.21595798432826996, 0.21050265431404114, 0.2032007873058319, 0.1977710872888565, 0.19237717986106873, 0.18970414996147156, 0.18382485210895538, 0.17890846729278564, 0.17379701137542725, 0.17074914276599884, 0.1664140522480011, 0.16357380151748657, 0.16041472554206848, 0.15632158517837524, 0.15332695841789246, 0.15161669254302979, 0.14730578660964966, 0.1456577479839325, 0.1434965878725052, 0.14018604159355164, 0.1377878487110138, 0.1372154802083969, 0.13389164209365845, 0.13224458694458008, 0.1302614063024521, 0.12803997099399567, 0.12660382688045502, 0.12484641373157501, 0.12347628176212311, 0.12122073769569397, 0.12071841955184937, 0.11853554844856262, 0.11960755288600922, 0.11623501032590866, 0.11406122148036957, 0.11343781650066376, 0.11221292614936829, 0.11080607026815414, 0.10987840592861176, 0.10837681591510773]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6945800185203552,\n",
       "  0.8684999942779541,\n",
       "  0.8918200135231018,\n",
       "  0.9028199911117554,\n",
       "  0.9107800126075745,\n",
       "  0.9167199730873108,\n",
       "  0.9218599796295166,\n",
       "  0.9257599711418152,\n",
       "  0.9294599890708923,\n",
       "  0.9321600198745728,\n",
       "  0.9344199895858765,\n",
       "  0.9370200037956238,\n",
       "  0.9388800263404846,\n",
       "  0.9412199854850769,\n",
       "  0.9429000020027161,\n",
       "  0.945360004901886,\n",
       "  0.9465600252151489,\n",
       "  0.9479799866676331,\n",
       "  0.9495999813079834,\n",
       "  0.9514999985694885,\n",
       "  0.952239990234375,\n",
       "  0.953760027885437,\n",
       "  0.9552000164985657,\n",
       "  0.9562399983406067,\n",
       "  0.9574999809265137,\n",
       "  0.9582800269126892,\n",
       "  0.9597799777984619,\n",
       "  0.9609799981117249,\n",
       "  0.9616199731826782,\n",
       "  0.9626399874687195,\n",
       "  0.9637600183486938,\n",
       "  0.9647600054740906,\n",
       "  0.9654399752616882,\n",
       "  0.9666399955749512,\n",
       "  0.9672999978065491,\n",
       "  0.967739999294281,\n",
       "  0.9690600037574768,\n",
       "  0.9696800112724304,\n",
       "  0.9700599908828735,\n",
       "  0.9709200263023376,\n",
       "  0.9714199900627136,\n",
       "  0.9724599719047546,\n",
       "  0.9728400111198425,\n",
       "  0.9733399748802185,\n",
       "  0.9739199876785278,\n",
       "  0.9739999771118164,\n",
       "  0.9749600291252136,\n",
       "  0.9755799770355225,\n",
       "  0.9764999747276306,\n",
       "  0.9767400026321411],\n",
       " 'loss': [1.2584397792816162,\n",
       "  0.5160437226295471,\n",
       "  0.39521539211273193,\n",
       "  0.34472790360450745,\n",
       "  0.31485581398010254,\n",
       "  0.293353408575058,\n",
       "  0.2763301134109497,\n",
       "  0.2628348171710968,\n",
       "  0.2506573796272278,\n",
       "  0.2402171492576599,\n",
       "  0.23099656403064728,\n",
       "  0.22229896485805511,\n",
       "  0.2146027684211731,\n",
       "  0.2073110193014145,\n",
       "  0.2004627138376236,\n",
       "  0.19395066797733307,\n",
       "  0.18827152252197266,\n",
       "  0.18224455416202545,\n",
       "  0.17703834176063538,\n",
       "  0.17167718708515167,\n",
       "  0.16705311834812164,\n",
       "  0.16228224337100983,\n",
       "  0.1578843593597412,\n",
       "  0.15363405644893646,\n",
       "  0.14965282380580902,\n",
       "  0.14590393006801605,\n",
       "  0.14216426014900208,\n",
       "  0.1385604441165924,\n",
       "  0.13529743254184723,\n",
       "  0.13203191757202148,\n",
       "  0.1288105696439743,\n",
       "  0.12567877769470215,\n",
       "  0.1228688508272171,\n",
       "  0.12000974267721176,\n",
       "  0.11722682416439056,\n",
       "  0.11469216644763947,\n",
       "  0.11208339035511017,\n",
       "  0.10971610993146896,\n",
       "  0.10714930295944214,\n",
       "  0.10495086014270782,\n",
       "  0.10289493203163147,\n",
       "  0.10054659098386765,\n",
       "  0.09846752136945724,\n",
       "  0.09650889039039612,\n",
       "  0.09438853710889816,\n",
       "  0.0926533192396164,\n",
       "  0.09068030118942261,\n",
       "  0.08901044726371765,\n",
       "  0.08727600425481796,\n",
       "  0.08549806475639343],\n",
       " 'val_accuracy': [0.8673999905586243,\n",
       "  0.8974999785423279,\n",
       "  0.9100000262260437,\n",
       "  0.9161999821662903,\n",
       "  0.9204999804496765,\n",
       "  0.9241999983787537,\n",
       "  0.9296000003814697,\n",
       "  0.9301999807357788,\n",
       "  0.932200014591217,\n",
       "  0.9372000098228455,\n",
       "  0.939300000667572,\n",
       "  0.9408000111579895,\n",
       "  0.9435999989509583,\n",
       "  0.944599986076355,\n",
       "  0.9470999836921692,\n",
       "  0.9483000040054321,\n",
       "  0.9502000212669373,\n",
       "  0.9510999917984009,\n",
       "  0.9526000022888184,\n",
       "  0.9534000158309937,\n",
       "  0.9544000029563904,\n",
       "  0.9542999863624573,\n",
       "  0.9559999704360962,\n",
       "  0.9562000036239624,\n",
       "  0.9580000042915344,\n",
       "  0.9581000208854675,\n",
       "  0.9598000049591064,\n",
       "  0.960099995136261,\n",
       "  0.9603000283241272,\n",
       "  0.9610999822616577,\n",
       "  0.9625999927520752,\n",
       "  0.9624000191688538,\n",
       "  0.9628000259399414,\n",
       "  0.963699996471405,\n",
       "  0.9642999768257141,\n",
       "  0.9650999903678894,\n",
       "  0.9652000069618225,\n",
       "  0.9656000137329102,\n",
       "  0.9661999940872192,\n",
       "  0.9670000076293945,\n",
       "  0.9666000008583069,\n",
       "  0.967199981212616,\n",
       "  0.967199981212616,\n",
       "  0.9682000279426575,\n",
       "  0.968500018119812,\n",
       "  0.9689000248908997,\n",
       "  0.9688000082969666,\n",
       "  0.9692000150680542,\n",
       "  0.970300018787384,\n",
       "  0.9700000286102295],\n",
       " 'val_loss': [0.5969629883766174,\n",
       "  0.39324304461479187,\n",
       "  0.33085760474205017,\n",
       "  0.2994612455368042,\n",
       "  0.27902182936668396,\n",
       "  0.2642807960510254,\n",
       "  0.2509019672870636,\n",
       "  0.2420831024646759,\n",
       "  0.23341354727745056,\n",
       "  0.22381117939949036,\n",
       "  0.21595798432826996,\n",
       "  0.21050265431404114,\n",
       "  0.2032007873058319,\n",
       "  0.1977710872888565,\n",
       "  0.19237717986106873,\n",
       "  0.18970414996147156,\n",
       "  0.18382485210895538,\n",
       "  0.17890846729278564,\n",
       "  0.17379701137542725,\n",
       "  0.17074914276599884,\n",
       "  0.1664140522480011,\n",
       "  0.16357380151748657,\n",
       "  0.16041472554206848,\n",
       "  0.15632158517837524,\n",
       "  0.15332695841789246,\n",
       "  0.15161669254302979,\n",
       "  0.14730578660964966,\n",
       "  0.1456577479839325,\n",
       "  0.1434965878725052,\n",
       "  0.14018604159355164,\n",
       "  0.1377878487110138,\n",
       "  0.1372154802083969,\n",
       "  0.13389164209365845,\n",
       "  0.13224458694458008,\n",
       "  0.1302614063024521,\n",
       "  0.12803997099399567,\n",
       "  0.12660382688045502,\n",
       "  0.12484641373157501,\n",
       "  0.12347628176212311,\n",
       "  0.12122073769569397,\n",
       "  0.12071841955184937,\n",
       "  0.11853554844856262,\n",
       "  0.11960755288600922,\n",
       "  0.11623501032590866,\n",
       "  0.11406122148036957,\n",
       "  0.11343781650066376,\n",
       "  0.11221292614936829,\n",
       "  0.11080607026815414,\n",
       "  0.10987840592861176,\n",
       "  0.10837681591510773]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69458</td>\n",
       "      <td>1.258440</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.596963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86850</td>\n",
       "      <td>0.516044</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.393243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.89182</td>\n",
       "      <td>0.395215</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.330858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90282</td>\n",
       "      <td>0.344728</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.299461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91078</td>\n",
       "      <td>0.314856</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.279022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91672</td>\n",
       "      <td>0.293353</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.264281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.92186</td>\n",
       "      <td>0.276330</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.250902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92576</td>\n",
       "      <td>0.262835</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.242083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92946</td>\n",
       "      <td>0.250657</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.233414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93216</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.223811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93442</td>\n",
       "      <td>0.230997</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.215958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93702</td>\n",
       "      <td>0.222299</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>0.210503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93888</td>\n",
       "      <td>0.214603</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.203201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94122</td>\n",
       "      <td>0.207311</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.197771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94290</td>\n",
       "      <td>0.200463</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.192377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94536</td>\n",
       "      <td>0.193951</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.189704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94656</td>\n",
       "      <td>0.188272</td>\n",
       "      <td>0.9502</td>\n",
       "      <td>0.183825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94798</td>\n",
       "      <td>0.182245</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.178908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.94960</td>\n",
       "      <td>0.177038</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.173797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95150</td>\n",
       "      <td>0.171677</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.170749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95224</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.166414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95376</td>\n",
       "      <td>0.162282</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>0.163574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95520</td>\n",
       "      <td>0.157884</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.160415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95624</td>\n",
       "      <td>0.153634</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.156322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95750</td>\n",
       "      <td>0.149653</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.153327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95828</td>\n",
       "      <td>0.145904</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.151617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.95978</td>\n",
       "      <td>0.142164</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.147306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96098</td>\n",
       "      <td>0.138560</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.145658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96162</td>\n",
       "      <td>0.135297</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.143497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96264</td>\n",
       "      <td>0.132032</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>0.140186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96376</td>\n",
       "      <td>0.128811</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.137788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96476</td>\n",
       "      <td>0.125679</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.137215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96544</td>\n",
       "      <td>0.122869</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.133892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96664</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.9637</td>\n",
       "      <td>0.132245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96730</td>\n",
       "      <td>0.117227</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.130261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96774</td>\n",
       "      <td>0.114692</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.128040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96906</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.126604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.96968</td>\n",
       "      <td>0.109716</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.124846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97006</td>\n",
       "      <td>0.107149</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.123476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97092</td>\n",
       "      <td>0.104951</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.121221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97142</td>\n",
       "      <td>0.102895</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.120718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97246</td>\n",
       "      <td>0.100547</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.118536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97284</td>\n",
       "      <td>0.098468</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.119608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97334</td>\n",
       "      <td>0.096509</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.116235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97392</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.114061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97400</td>\n",
       "      <td>0.092653</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.113438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97496</td>\n",
       "      <td>0.090680</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.112213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.089010</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.110806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97650</td>\n",
       "      <td>0.087276</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.109878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97674</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.108377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.69458  1.258440        0.8674  0.596963\n",
       "1    0.86850  0.516044        0.8975  0.393243\n",
       "2    0.89182  0.395215        0.9100  0.330858\n",
       "3    0.90282  0.344728        0.9162  0.299461\n",
       "4    0.91078  0.314856        0.9205  0.279022\n",
       "5    0.91672  0.293353        0.9242  0.264281\n",
       "6    0.92186  0.276330        0.9296  0.250902\n",
       "7    0.92576  0.262835        0.9302  0.242083\n",
       "8    0.92946  0.250657        0.9322  0.233414\n",
       "9    0.93216  0.240217        0.9372  0.223811\n",
       "10   0.93442  0.230997        0.9393  0.215958\n",
       "11   0.93702  0.222299        0.9408  0.210503\n",
       "12   0.93888  0.214603        0.9436  0.203201\n",
       "13   0.94122  0.207311        0.9446  0.197771\n",
       "14   0.94290  0.200463        0.9471  0.192377\n",
       "15   0.94536  0.193951        0.9483  0.189704\n",
       "16   0.94656  0.188272        0.9502  0.183825\n",
       "17   0.94798  0.182245        0.9511  0.178908\n",
       "18   0.94960  0.177038        0.9526  0.173797\n",
       "19   0.95150  0.171677        0.9534  0.170749\n",
       "20   0.95224  0.167053        0.9544  0.166414\n",
       "21   0.95376  0.162282        0.9543  0.163574\n",
       "22   0.95520  0.157884        0.9560  0.160415\n",
       "23   0.95624  0.153634        0.9562  0.156322\n",
       "24   0.95750  0.149653        0.9580  0.153327\n",
       "25   0.95828  0.145904        0.9581  0.151617\n",
       "26   0.95978  0.142164        0.9598  0.147306\n",
       "27   0.96098  0.138560        0.9601  0.145658\n",
       "28   0.96162  0.135297        0.9603  0.143497\n",
       "29   0.96264  0.132032        0.9611  0.140186\n",
       "30   0.96376  0.128811        0.9626  0.137788\n",
       "31   0.96476  0.125679        0.9624  0.137215\n",
       "32   0.96544  0.122869        0.9628  0.133892\n",
       "33   0.96664  0.120010        0.9637  0.132245\n",
       "34   0.96730  0.117227        0.9643  0.130261\n",
       "35   0.96774  0.114692        0.9651  0.128040\n",
       "36   0.96906  0.112083        0.9652  0.126604\n",
       "37   0.96968  0.109716        0.9656  0.124846\n",
       "38   0.97006  0.107149        0.9662  0.123476\n",
       "39   0.97092  0.104951        0.9670  0.121221\n",
       "40   0.97142  0.102895        0.9666  0.120718\n",
       "41   0.97246  0.100547        0.9672  0.118536\n",
       "42   0.97284  0.098468        0.9672  0.119608\n",
       "43   0.97334  0.096509        0.9682  0.116235\n",
       "44   0.97392  0.094389        0.9685  0.114061\n",
       "45   0.97400  0.092653        0.9689  0.113438\n",
       "46   0.97496  0.090680        0.9688  0.112213\n",
       "47   0.97558  0.089010        0.9692  0.110806\n",
       "48   0.97650  0.087276        0.9703  0.109878\n",
       "49   0.97674  0.085498        0.9700  0.108377"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGyCAYAAACiMq99AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5YUlEQVR4nO3dd5wU9eH/8ddsv144uIOjKkWQIoIgdgUkkhCNGhtRY6KJiRiV+DPhGxX9JkZNol+NJURjTcQSE40JRkUUKzYUlXYUaQJ3cL1vm/n9Mbt7d3Bl97jCHe/n9zuPmZ2d2fnszR2+82ljWJZlISIiIiLSBRzdXQAREREROXQofIqIiIhIl1H4FBEREZEuo/ApIiIiIl1G4VNEREREuozCp4iIiIh0GYVPEREREekyCp8iIiIi0mUUPkVERESkyyh8ioiIiEiXSTh8vv3228yZM4cBAwZgGAYvvvhim+csX76co48+Gq/Xy/Dhw3n88cfbUVQRERER6ekSDp81NTVMmDCBBx54IK7jt2zZwje/+U1OPfVUVq1axbXXXsvll1/Oq6++mnBhRURERKRnMyzLstp9smHwwgsvcNZZZ7V4zC9+8QuWLFnC6tWrY/suuOACysvLeeWVV9p7aRERERHpgVydfYEVK1YwY8aMJvtmzZrFtdde2+I5fr8fv98fe22aJqWlpfTp0wfDMDqrqCIiIiLSTpZlUVVVxYABA3A4Wm5c7/TwWVhYSG5ubpN9ubm5VFZWUldXR1JS0n7n3H777dx6662dXTQRERER6WA7duxg4MCBLb7f6eGzPRYsWMD8+fNjrysqKhg8eDBbtmwhLS2t068fDAZ58803OfXUU3EHKnD/6Rh7/883g6EJAnqSJvfS7e7u4sgB0L3sPXQvew/dy96jI+5lVVUVw4YNazOrdXr4zMvLo6ioqMm+oqIi0tPTm631BPB6vXi93v32Z2dnk56e3inlbCwYDJKcnEyfPn1wm6ngjTT1p6eAJ7nTry8dp8m91D+MPZruZe+he9l76F72Hh1xL6PntdVFstOr8aZNm8ayZcua7Fu6dCnTpk3r7Et3DHejgBys7b5yiIiIiPQCCYfP6upqVq1axapVqwB7KqVVq1axfft2wG4yv+SSS2LHX3nllXz11VfccMMNrF+/ngcffJDnnnuO6667rmO+QWdzOMHls7cVPkVEREQOSMLh85NPPmHixIlMnDgRgPnz5zNx4kRuvvlmAHbv3h0LogDDhg1jyZIlLF26lAkTJnDXXXfxl7/8hVmzZnXQV+gC0drPYF33lkNERESkh0u4z+cpp5xCa1ODNvf0olNOOYXPPvss0UsdPNzJUFcGgZruLomIiIhIj6ah2/FwRwYZqeZTRERE5IAclFMtHXTU7C4iIiItCIVN/KHoEiYQMgmGTYJhi1DYIhA2CYVNQmZ02yIUNmPbgbCJPxje7zP8IRN/0H4dfS8YNrEsMC0rstiTu5uxfdHXFqYJ3xzfn6tOHd7dP6ImFD7jEav5VLO7iIhIPCwrEqpCJvXBcCxEhUyLcKPFtOyAFo6EpZBpYloWYRPCphk7Phi2Wn4dtgiaVizgBaMBz4wGQDP2fvRc07KwLLCwIuW1F7D3NWxHvkuoIWDWR4NiZB0y2/2k8k43aUhWdxdhPwqf8fCo2V1ERLpPOBqoTItgyCRompgmhC07eIWtZgJdo+1gyMQfNgmEzFiIsrfDDdvhhv0h02wU8OzPiga76DpsWgRCYfaWOPnTV+/jD1vUB8ORxQ6aB3Em6zRup4Hb6YgsBi6HA7fLwO1w4Iq853I6cDui2wZelxOv24HbaeJyhXE5QzidIZyOIIYzhMMRxHAEwQiCYeJyOHE6nDgMA6fhxGk4cDjsdXSJvh7Rx9PdP5L9KHzGI1bzqamWRER6s2jIizaZNrcdrZ2LhjLTbAh6jWv1QqZJXSBMTSBMXSBEbSAcWZpuR4/xh8KEwlbsWo1r67omxJlghO3FMgBHw7rVISIGVFc3em01fJbDxDDCGI4wXhd43BYuw8AwDFwOA8Nh4HSAEwOHw8DpMHAYkcVh4HSYGI4gDmcIwwjhcITAiAaxUGQJYEW2DcPEMKzIGgzsNYYJhmW/hwkGQBjTMrEwMa0wJiaWZWLG9kfWlomJicMgUjZHZA0OhyMSAA0cDgfOyHezLIuwZZ8fMkOYlknYCtuLGcZvham1wpimScgK4Q/78Yf8hIKhDr+r5486n+OG3tjhn3sgFD7joT6fIiKdzrKsWB+3+lC4yTraZy4azAKxUNgoGIbsbX8oTF3QDnf1wTB1gX1eR/dF9jcJli2GvEaByghjGKHIdgjDEQ1B++w3wpHzrEjYiX7OPmujYdswTHBZ4DYj1zNxYuIyLCAcOdbe73CYGIaJwxHGYZjgCEdCV8PaDl3hyL4QOMKAXV7LCGFhLyYhLMKt3h8HTgzDgQMHDsOJw3Bg4CAcCmG4wLTChK0QYavlzzGBQGTb3+rV2mAeyMkHPwMDn8uH1+nF5/Lhc/pir52GE4tIuDXtYGxazS9hK0yWT83uPVM0fAZU8ykih46waQe5+mBDH7dos2rDdmQwRNCkLtgQ7moDIWqDdVT7a6gO1VAXrKU2VEt92F4qa6q47cECQmEiwQ9CYQs7pRlgGVjRbQzADlp28GoIYEZkbYc4O+wZRhgc0ZqwSA2ZIxQJhpG1LwTJoVhYdBphXJiRENkQ2OzPtsNcQ0g8eEWibqcwCYMVtiNq44sY0EZuxWE4cBkunA4nBq0/erExp8OJz+nD4/Tgc/rwurx4nU0Xn8t+PxrM7JpJB07DiRFplo6um7yHgdPhxGW4IrWWztgxLocrdlx0n/21rdh0k1bk/7AathtPRRn7bMOB0+GMfda+2w7DYX+3aNB0+fA4PG0+orInU/iMhzvFXqvZXUS6SShsUlZXw56acoprKympraSsrpLqQD31oRD+YMheh0L4w2H8wSCBsN2UGwgHCYTCBMLhSN/AMGHTJGyZkb6BkVqS6NoyMU0Lk+Zq8yLbjkjNXuMaP4cfI7LgCGDsG9ZcNPxXJ7npW+7I0pN4HB48Tg9uhxu3093kdXRtGAYGRmwNdq2W/f/7vGdgB7RGAaW5IBR9z+VwNSyGC7fTjcto2Od2uJtsNy5brKxOt70v8trj9OByuGLNxtFm4ujatOxm4mitmj/g55133uG0k0/D5/E1e+1o6BSJUviMh5rdRaQZdcF69tZWUFxTQUltBaX1FZTVV1JRX0VlwF5qglX4Q4FGIc+KhLzo6F67qTca+MJWmIBZR9CqJWTVETbqsIx6cNRHav7aqa1ue404I0vHMPAYPjzOJHzOZHzOZLxOH3VVtWRmZuBwEOmbZ0UCWbQ/nhWZLsZuVmyuBsnhcMT2RwOaw3DgdrhjtWJuZ8N2NGB5nd5Y0PI4PE2D0r7BqfHrSMDzOOyA1ptrpuIVDAbZ4NzAkPQhuN097X8+SHdR+IyHploS6TKWZRE0g9SH6wmEA9SH7HW1v5qvQ1+zpmQNbpe7+ZqjiGiH/yp/NcV1lZTUVlBeX0V5fSUV/mqqAlVUB6upCdZQG6qmPlxLyAxE5sgzIwMPIlOxRLbtNfYaE8uot/v6dTSD/ZJf44hjWQaG5cUwfThJwml4YrVidjiL1JA5HJERsfY6ujgNR2RQR2RUbHTAhCP6GfboXIfDgcfpwufykOTy4nV5mtSOuR3uhlq0SIhLdieT4k4h2WWvU9wp+Fy+WJNlVDAY5OWXX2b27NkKLCKHIIXPeGiqJTnEWZZFXaiOmmBNJLDV2uugva4JNWzXh+sJhoMEwgECZoCgaW8Hw0ECZsDeHw7gDweoDwXwh/2RY+2QGTQDsXn3mrPo1UVd98WNfdbNvAVghb1gJuGwknCQjIsk3EYyHkcKXkcyHqcnFvScDjvc2aHQaNhnOHA6HbgdDtI8aWT4UsnypZPlSycnOZ0+yen0S80k05eiJkwR6dEUPuOhZnfpIUzLpCZYQ1WgispAZdO1v5KqYBVVgSrqQnUNoS/cEAD9YX8sIDbeVxusbTUQdhbLMsBygenGslxgOWJNspEjmq6bvAeYXqywDyy7ltAdCYVeZwpeZzJJTrt2LsWVSpLbi9flwuN04HW7Yts+lwuvy4nH5bS33U58bhfZvnRykjPISU4n2ePG4VATrIhIPBQ+4xFtdg+o2V06R32onrL6Mkr9pfa6vpTqQDX14XrqQnXUh+x1dLu5/ZWBSqoD1Z0bEi0Dy/RimR4s02uHuybb3kZB0QmWa59tJ5iu2LaBC5fhwW14cTk8uB0e3E4PbocXr8OLx+XG43TicTpwOaCibC+HD84nLclDitdFqtdFisfZsB1ZUr0ukj3O2D6PK87OjiIi0ukUPuPhVrO77C9oBqkN1sb6JNaH6+2JgiOTBUe3o30X60J1lNY3hMvourS+lNpQB8+kYLkgnIQZTsIK+7BMH1Y4Ccu0X2N6I6HQBaYrtm1ZbjCdYLkb9pmuhmBpuWnc4Ox1OUjzNQS+1CQXaT43GUlu0pNcpPvcpCdFXvtcpCe5Sfe5yUi2X6d4XHHXGDb0ExynfoIiIj2Ywmc89ISjQ4ZpmVT4KyiuK44tJXUl9nZ909fl/vIOvbaBEzfpuKw0DDOFcMhHIOjCH3RGahfdYHqwLHeTbUwPlumBWMD0RULiPp9vQJLbSZLbSbLXSYrHrh1MidQSpnjsENnce2k+F6leN6leV2RbNYoiItI+Cp/xUJ/PHiFoBqn0V1IRqLDX/gpKa0v50P8hu9fspj5cHxss09xAmejS2tM5muPAicvw4DDcGJYHK1JbaIZdhMJOQiEnpum2axPDKVihFKxwKlYoBTOytsKpYHppdmRLRLrPRU6ql+wUD9kpHvqkeiLbXrKS3aR4XXa49DibriPbXpdDU8OIiEi3U/iMRyx8quazO1iWRVFtEZvKN7G5fDPbK7dT7i9vEjIrAhXUtDYV1ueJXdNFKi4rHcNMxwqlEQqk4PenEPCnYoVSscJpWKE0uwk7zhkRkz1O0n1uUn0uUpPtGsQ0n4s0r70vWqNo77ebqrNTPPRJ8ZCV4sHtVC2jiIj0fAqf8fDoCUddIRoyN5dvjgXNzRWb+ar8K6qD1XF9hoFBkisVnyMVj5GK00qmptrE680kGPTgD7ip8zuprXdHBsd4IgNoGgbMWKEU2vrTSPO6SE+z+zNGw2F2sttep3jISm66zkx243NrehwRERGFz3io2b3d6kP1VPgrqAxU2ou/smE7UBl7b0fVjlZDpgMnGa7+JBv5OMO5hIOp1NV7qav3UFXrod7vxQong+mjMs7HuDgM7JrFNC85aR76pNhN2vZgmaYDZBoPnkn1unBqWh0REZF2UfiMR3TAUagezDAcIhM8V/gr2Fi2kYKyAjaWbaTCX0HIDBG0gvY6HCRkhQiZ+y/+sJ+qQBUBM5DYRS0HBHMI1vfD9Oc2LIE+VLTx6+pyGGSlechKdpOZ7CE72UNGkpOS3TuYOmE0uRnJ5KR46JPqJSfVQ2ayRyFSRESkiyl8xiMaPsGu/fSmdl9ZOkHIDLG9cjsbyjbEloKyAgprCjvoCgYuUrDCSYSCPsKhxtP+RJZgJmYgF9OfQ/TX0u006JvqJaevHRZzUr30TfPSJ9VLdoqbrGRPw5Ji10juO6DGnp5nG7On6bnDIiIiBwOFz3i4fA3bPTR8hs0we+v2srtmNzurd7Krehc7qnawoWwDm8s34w/7mz1vQMoARmaNZETWCPol98PtcGNZDirrTMprTMpqQ5RUhSmpDrOnKkRxRZCaAGA5YwGzuVHcOake8rOSGdgviYGZSeRl+MhJ9UYCpoe+qT7Sk/YPkyIiItKzKXzGw+EAVxKE6iBYA/Tt7hLtx7RM9tTu4euqr5sEzF01u9hVvYvdNbsJmaEWz09yJTEicwQjs0faYTNzBBnOwewshQ1FVRRsqubtkhq2l9ayp6r5oNpY3zQvA7OSGJiVzMCsJPIzk2Kv8zOTSPIcGl0XREREpCmFz3h5kiPhs/sGHVmWxZ7aPWyv2s72yu1sq9pmryu38XXV19SH61s932k4yUvJY0DqAPqn9Gdg6kCGZw0n13cYVVXpbNpTQ0FhFf9YVUVBUQlV9UUtflaq18Wg7GQGZSUxODvZ3s62twdmJWtkt4iIiDRL4TNe7mSgpEumW7Isi53VO1ldspqC0gK2VW5jW+U2dlTtoC7Ucvh1Gk76p/QnPzWfAakDGpaUAeSn5tPHl8PO8gBf7qxg9c4K3l1fwSOF1RRXr2/+8xwGh+WkMDIvjVG5aRzWN8UOmlnJZCa71SQuIiIiCVP4jFcnTrdUXFfM6uLV9lKymjXFa1p8dKPTcDIgdQCD0wczOG0wQ9KHxNb9U/vjdtiDakzTYktJDat3VvDq+gq+3LmVNTu/oMrffNP74OxkRuamMSovNbJOY1hOCl6XajBFRESk4yh8xisaPgMHVvNZE6zhy+IvG8Jm8WqKavdv3nY5XIzKGsWYPmMYljEsFjLzU/NxO/cftV1S7eeVL/eyakc5X+6sYO2uSqqbCZpel4PR/dMZl5/B2Px0jshLZ3i/VFK8+lUQERGRzqfEES/3gT3laG3JWp5Z/wwvb3l5v5HlBgaHZx7OkX2OZGzOWMbmjGVk1kg8Tk+Ln1cXCPPR1lLe21TMuxuLWbu7cr9jvC4HYwZEg2YG4/IzGN4vVY9pFBERkW6j8BmvdjS7B8IBXt36Ks8UPMMXe7+I7R+QMoBxfccxts9Yjsw5kjF9xpASDbctCJsWX+6s4L1NxbyzcS+fbisnEDabHHNEXhpThmUzLj+DcQMzGN43FZeCpoiIiBxEFD7jFQufNW0eurt6N89teI5/bvwnpfWlgN2MfvqQ07nwiAuZ0HdCXIN1iirreW1NIe9uKmbF5hIq65s2ow/I8HH88BxOGJHDcYfn0DfNm/j3EhEREelCCp/x8kSb3Zuv+bQsiw92f8Az659h+dfLMS27VjI3OZfzRp3H2SPOJicpp83L1AXCvLa2kH98upN3N+7FtBreS/O5OO7wPpwwPIfjh+cwLCdFI85FRESkR1H4jFcLze51oTr+ufGfPLP+GbZWbo3tn5o3lQuOuIBTBp2Cy9H6j9k0LT7aWso/P/2al78sbDJQaOLgTKYf0Y/jh+cwLj9DzegiIiLSoyl8xiv6fPdAQ7N7daCaK1+/ks/3fg5AijuFbx/+bS4YdQGHZR7W5kduKa7hhU+/5p+f7eTrsoZQOzAribOPHsjZE/MZmtN6X1ARERGRnkThM17R8Bmp+awJ1vCT13/C53s/J92Tzs8m/oxvHf6tNgcOVdQG+c+Xu/jHyq/5dHt5bH+q18U3x/Xn7KPzOWZoNg6HmtNFRESk91H4jFes2b02FjxX7V1FmieNh09/mDF9xrT5EUvXFjH/uVVURQYOOQw4aWRfzj56IDNH5+p55yIiItLrKXzGK1LzWRuo4qev/5TP9nwWd/AMmxb/t3QD97+5CYDh/VI5f/IgzjxqAP3SfZ1edBEREZGDhcJnvDzJ1BoGP61bz6e1taS503ho5kMc2efIVk8rrQlwzTOf8c7GYgC+f9xQ/mf2aDwuDRwSERGRQ4/CZ5xqHS7m5fZlpVVLqjuVP8/8M2NzxrZ6zuc7yvnpU5+ys7yOJLeTO84Zx5lH5XdRiUVEREQOPgqfcagL1XH1lr/zcZKPFMvgzzP/zLi+41o83rIsnvl4Bwv/tYZA2GRYTgqLvjeJUXlpXVhqERERkYOPwmcb6kJ1XL3saj6q+ooU02RRII3xfce3eHx9MMzN/1rNc598DcDMMbncdd4E0n3uriqyiIiIyEFL4bMV9aF6rnvnOj4s/JBkp5dFu7ZxVErLj7DcUVrLT55ayeqdlTgMuH7WKK486XBNmyQiIiISofDZgqAVZP7b8+3g6Upm0cSfc9SmK8DT/OM1lxfs4dpnV1FeGyQ7xcMfL5jICSPafpymiIiIyKFE4bMZ/rCfp2qeYlPFJpJcSfxpxp+Y6Ei13wzWNDnWNC3uf3MT//f6BiwLJgzM4MHvTSI/M6kbSi4iIiJycFP43Ic/7Ofnb/+cTaGG4Hl07tFQYffh3PfZ7ove3szdSzcAcNHUwSycMwavS5PFi4iIiDRH4XMfK3at4P3d7+PGzR9P/iOTcifZb0QfrxkOQDgETvtHt7xgLwDXzRjJNTNGdEeRRURERHoMhc99nDLoFG6cciO71uxqCJ7Q8HhNgGAtONOxLIsNRVUATB/dr4tLKiIiItLz6DE7zTh7+Nkc5j6s6U6XD4iMWo80ve+t8lNeG8Rh2I/MFBEREZHWKXzGyzAamt6DtQAURGo9h/ZJwedWP08RERGRtih8JiLa9B6p+SwotMPnyFw9uUhEREQkHgqfidin5jPa33OkHpspIiIiEheFz0R49m12rwZglGo+RUREROKi8JmIRs3upmmxMVLzOSpPg41ERERE4qHwmYhos3ughp3lddQGwnicDob0SenecomIiIj0EAqfiYj1+ayLDTY6rG8Kbqd+jCIiIiLx0CTziYg1u9dSUB5tcld/TxEREZF4qcouEY1Gu8dGumuwkYiIiEjcFD4T4dm/2V0j3UVERETip/CZiEjNZ9hfw1d7awA1u4uIiIgkQuEzEZE+n1XVlQTCJskeJ/mZSd1cKBEREZGeQ+EzEdHwWVkJwIjcNBwOoztLJCIiItKjKHwmwm3P51lTE+3vqcnlRURERBKh8JmISM2nv9Z+rKZGuouIiIgkRuEzEY0GHIEGG4mIiIgkSuEzEZ6GeT5B0yyJiIiIJErhMxGRZvckAmQmu+mb5u3mAomIiIj0LAqfiYg0uyfhZ2RuGoahke4iIiIiiWhX+HzggQcYOnQoPp+PqVOn8tFHH7V6/D333MOoUaNISkpi0KBBXHfdddTX17erwN0qGj4Nv5rcRURERNoh4fD57LPPMn/+fBYuXMinn37KhAkTmDVrFnv27Gn2+MWLF/PLX/6ShQsXsm7dOh555BGeffZZ/ud//ueAC9/lYjWfAUZqsJGIiIhIwhIOn3fffTdXXHEFl112GWPGjGHRokUkJyfz6KOPNnv8+++/z/HHH89FF13E0KFDOf3007nwwgvbrC09KMX6fKrmU0RERKQ9XIkcHAgEWLlyJQsWLIjtczgczJgxgxUrVjR7znHHHcff/vY3PvroI6ZMmcJXX33Fyy+/zMUXX9zidfx+P36/P/a6MvJEoWAwSDAYTKTI7RK9xr7Xqg44yALcRphhGc4uKYscmJbupfQ8upe9h+5l76F72Xt0xL2M99yEwmdxcTHhcJjc3Nwm+3Nzc1m/fn2z51x00UUUFxdzwgknYFkWoVCIK6+8stVm99tvv51bb711v/2vvfYaycnJiRT5gCxdurTJ6+2VQa6ObH+0/GVCzq4rixyYfe+l9Fy6l72H7mXvoXvZexzIvaytrY3ruITCZ3ssX76c3/72tzz44INMnTqVTZs2cc011/DrX/+am266qdlzFixYwPz582OvKysrGTRoEKeffjrp6emdXWSCwSBLly5l5syZuN3u2P5nP95BeJOB07A4/ZQTIC2v08siB6aleyk9j+5l76F72XvoXvYeHXEvoy3VbUkofObk5OB0OikqKmqyv6ioiLy85oPYTTfdxMUXX8zll18OwLhx46ipqeFHP/oRv/rVr3A49u926vV68Xr3n0PT7XZ36S/3vtfbVFxHHV5SqcdtBUB/aD1GV//uSOfRvew9dC97D93L3uNA7mW85yU04Mjj8TBp0iSWLVsW22eaJsuWLWPatGnNnlNbW7tfwHQ6nQBYlpXI5bvdhqIq6oiE4mBd9xZGREREpAdKuNl9/vz5XHrppUyePJkpU6Zwzz33UFNTw2WXXQbAJZdcQn5+PrfffjsAc+bM4e6772bixImxZvebbrqJOXPmxEJoT7GhqIo6ywMGCp8iIiIi7ZBw+Dz//PPZu3cvN998M4WFhRx11FG88sorsUFI27dvb1LTeeONN2IYBjfeeCM7d+6kb9++zJkzh9tuu63jvkUXKK72U1wdoM4Trfms6d4CiYiIiPRA7RpwNG/ePObNm9fse8uXL296AZeLhQsXsnDhwvZc6qCxoagKgLArCUxU8ykiIiLSDnq2e5w2FNrh0+GJTK8UjG86ARERERFpoPAZp4KiagDcvhR7R0DhU0RERCRRCp9xija7+5Ijj9VUs7uIiIhIwhQ+42BZVqzZPTU1Gj5V8ykiIiKSKIXPOOyuqKfKH8LlMEhNizxhSTWfIiIiIglT+IxDQaTJfVhOCs7YgCNNtSQiIiKSKIXPOESb3EfmpYEnMuBINZ8iIiIiCVP4jEO05nNUbhq4k+ydCp8iIiIiCVP4jEN0pPvI3DRwR5rdA2p2FxEREUmUwmcbwqbFxsgcn6PyGoVP1XyKiIiIJEzhsw3bS2vxh0y8LgeDs5MbNbtrqiURERGRRCl8tqEgMthoRG4qTofRqOZT4VNEREQkUQqfbdjYuL8ngEfN7iIiIiLtpfDZhiYj3UE1nyIiIiIHQOGzDbGR7nnR8KmplkRERETaS+GzFYGQyVd77SmV9qv5DKjmU0RERCRRCp+t2FpSQ8i0SPO66J/hs3c2bna3rO4rnIiIiEgPpPDZig2R+T1H5qVhGIa9M9rsboUhHOymkomIiIj0TAqfrdiwJxI+o03u0FDzCRDUU45EREREEqHw2YrYk41yUxt2ujzgcNnbGnQkIiIikhCFz1bEaj7z0pq+oUdsioiIiLSLwmcL/GHYUWaHy1G5+4bPSL/PgJrdRURERBKh8NmCojp7MHtOqoc+qd6mb6rmU0RERKRdFD5bsLvWHt0+ct9aT9BTjkRERETaSeGzBa2Hz+hTjhQ+RURERBKh8NmC3ZFcOWrfwUYAHjW7i4iIiLSHwmcLdtep2V1ERESkoyl8NqOiLkhFIBo+U/c/INbsrppPERERkUQofDZjY2R+zwEZPtJ87v0PiNZ8aqolERERkYQofDYj+kz3Ec3VeoKmWhIRERFpJ4XPZkRrPkf2ayl8arS7iIiISHsofDYjWvPZbH9P0IAjERERkXZS+NyHZVmxms8RLdV8aqolERERkXZR+NzH3mo/ZbVBDCwO75vS/EGq+RQRERFpF1d3F+BgU1IdYGifZOpqa/C5nc0fFO3zGVD4FBEREUmEaj73Mbp/OkuvPYFfTAi3fJBGu4uIiIi0i8JnC5xGK2+q2V1ERESkXRQ+20NPOBIRERFpF4XP9ojVfOoJRyIiIiKJUPhsD021JCIiItIuCp/toWZ3ERERkXZR+GyPaLN7oAYsq3vLIiIiItKDKHy2RzR8YkHI361FEREREelJFD7bI9rsDppuSURERCQBCp/t4XSDw21vK3yKiIiIxE3hs7004l1EREQkYQqf7aWnHImIiIgkTOGzvTTdkoiIiEjCFD7bq/F0SyIiIiISF4XP9nKrz6eIiIhIohQ+20vN7iIiIiIJU/hsr1jNp5rdRUREROKl8NlemmpJREREJGEKn+0Va3bXVEsiIiIi8VL4bK/YaHeFTxEREZF4KXy2l0a7i4iIiCRM4bO99IQjERERkYQpfLaX+nyKiIiIJEzhs708qvkUERERSZTCZ3upz6eIiIhIwhQ+20tPOBIRERFJmMJne8WmWtITjkRERETipfDZXmp2FxEREUmYwmd7KXyKiIiIJMzV3QXosWJ9PtXsLiIiPZtlWYRCIcLhcELnBYNBXC4X9fX1CZ8rB5d47qXT6cTlcmEYxgFdS+GzvTyq+RQRkZ4vEAiwe/duamsTnzrQsizy8vLYsWPHAQcS6V7x3svk5GT69++Px+Np97XaFT4feOABfv/731NYWMiECRO47777mDJlSovHl5eX86tf/Yp//vOflJaWMmTIEO655x5mz57d7oJ3u8ZPOLIs0B+diIj0MKZpsmXLFpxOJwMGDMDj8SQUIk3TpLq6mtTUVBwO9eTrydq6l5ZlEQgE2Lt3L1u2bGHEiBHtvucJh89nn32W+fPns2jRIqZOnco999zDrFmzKCgooF+/fvsdHwgEmDlzJv369eP5558nPz+fbdu2kZmZ2a4CHzSize5g135Ga0JFRER6iEAggGmaDBo0iOTkxP87ZpomgUAAn8+n8NnDxXMvk5KScLvdbNu2LXZseyQcPu+++26uuOIKLrvsMgAWLVrEkiVLePTRR/nlL3+53/GPPvoopaWlvP/++7jdbgCGDh3arsIeVNyN/kgVPkVEpAdTcJR4dcTvSkLhMxAIsHLlShYsWNCkEDNmzGDFihXNnvPSSy8xbdo0rrrqKv71r3/Rt29fLrroIn7xi1/gdDqbPcfv9+P3+2OvKysrAbszbDAYTKTI7RK9RlvXcjm9GGE/wbpK8KR3erkkcfHeSzn46V72HrqXB49gMIhlWZimiWmaCZ9vWVZs3Z7z5eAR7700TRPLsggGg/vluHj/phMKn8XFxYTDYXJzc5vsz83NZf369c2e89VXX/HGG28wd+5cXn75ZTZt2sRPf/pTgsEgCxcubPac22+/nVtvvXW//a+99lq7mgUS4SovJ/Pdd+kbDrO0jWPPwIUHP28ve4Vq34BOLZccmKVL27qb0lPoXvYeupfdz+VykZeXR3V1NYFAoN2fU1VV1YGlku7U1r0MBALU1dXx9ttvEwqFmrwX76C1Th/tbpom/fr146GHHsLpdDJp0iR27tzJ73//+xbD54IFC5g/f37sdWVlJYMGDeL0008nPb1zaxgD27ax/fY7MN1uJvzxj3i83haPdW1Kh6oaTpo2Gfof1anlkvYJBoMsXbqUmTNnxrp9SM+ke9l76F4ePOrr69mxYwepqant6r9nWRZVVVWkpaVptHsPF++9rK+vJykpiZNOOmm/35loS3VbEgqfOTk5OJ1OioqKmuwvKioiLy+v2XP69++P2+1uUjU7evRoCgsLCQQCzQ7V93q9eJsJfW63u9P/oXINGQIuF45gEKOsDPegQS0f7Emxy2UFQf+AHtS64ndHuobuZe+he9n9wuEwhmHgcDja1Zcv2jwb/YxDWTAY7NG/z/HeS4fDgWEYzf79xvv9E/pN8Xg8TJo0iWXLljUp7LJly5g2bVqz5xx//PFs2rSpSf+BDRs2HPAcUZ3FcLtx5+cDENy2rfWDYxPNJz43moiIiLTfK6+8wgknnEBmZiZ9+vThW9/6Fps3b469//XXX3PhhReSnZ1NSkoKkydP5sMPP4y9/+9//5tjjjkGn89HTk4O3/nOd2LvGYbBiy++2OR6mZmZPP744wBs3boVwzB49tlnOfnkk/H5fDz11FOUlJRw4YUXkp+fT3JyMuPGjePpp59u8jmmafK73/2O4cOH4/V6GTx4MLfddhsAp512GvPmzWty/N69e/F4PE2yV0+X8P9MmT9/Pg8//DBPPPEE69at4yc/+Qk1NTWx0e+XXHJJkwFJP/nJTygtLeWaa65hw4YNLFmyhN/+9rdcddVVHfctOph7yBAgnvAZ6X8aUPgUEZHewbIsagOhuJe6QDih41taogNe4lVTU8P8+fP55JNPWLZsGQ6Hg+985zux+SpPPvlkdu7cyUsvvcTnn3/ODTfcEKsIW7JkCd/5zneYPXs2n332GcuWLWt1vvKW/PKXv+Saa65h3bp1zJo1i/r6eiZNmsSSJUtYvXo1P/rRj7j44ov56KOPYucsWLCAO+64g5tuuom1a9eyePHi2Fiayy+/nMWLFzcZdP23v/2N/Px8TjvttITLd7BKuM/n+eefz969e7n55pspLCzkqKOO4pVXXon94LZv396kunbQoEG8+uqrXHfddYwfP578/HyuueYafvGLX3Tct+hg7sGDAQhu297GgXrKkYiI9C51wTBjbn61y6+79n9nkeyJP5acc845TV4/+uij9O3bl7Vr1/L++++zd+9ePv74Y7KzswEYPnx47NjbbruNCy64oMng5gkTJiRc5muvvZazzz67yb7rr78+tn311Vfz6quv8txzzzFlyhSqqqq49957uf/++7n00ksBOPzwwznhhBMAOPvss5k3bx7/+te/OO+88wB4/PHH+f73v9+r+tS2a8DRvHnz9qsWjlq+fPl++6ZNm8YHH3zQnkt1C89Qu+YzsG1r6wc2fsqRiIiIdJmNGzdy88038+GHH1JcXByr1dy+fTurVq1i4sSJseC5r1WrVnHFFVcccBkmT57c5HU4HOa3v/0tzz33HDt37iQQCOD3+2Mz9axbtw6/38/06dOb/Tyfz8fFF1/Mo48+ynnnncenn37K6tWreemllw64rAcTPdu9GQ3N7m3VfKrPp4iI9C5Jbidr/3dWXMeapklVZRVp6WkHPOAoyd383N8tmTNnDkOGDOHhhx9mwIABmKbJ2LFjCQQCJCUltXpuW+8bhrFfN4Dm5rBMSUlp8vr3v/899957L/fccw/jxo0jJSWFa6+9NjaNVVvXBbvp/aijjuLrr7/mscce47TTTmNIJJf0Fof20LQWxMLn119j7TOHVRMe1XyKiEjvYhgGyR5X3EuSx5nQ8S0tiTQrl5SUUFBQwI033sj06dMZPXo0ZWVlsffHjx/PqlWrKC0tbfb88ePHtzqAp2/fvuzevTv2euPGjXHNYfnee+9x5pln8r3vfY8JEyZw2GGHsWHDhtj7I0aMICkpqdVrjxs3jsmTJ/Pwww+zePFifvCDH7R53Z5G4bMZrtxcTJcLQiGCu3a1fKD6fIqIiHS5rKws+vTpw0MPPcSmTZt44403mswPfuGFF5KXl8dZZ53Fe++9x1dffcU//vGP2NMYFy5cyNNPP83ChQtZt24dX375JXfeeWfs/NNOO43777+fzz77jE8++YQrr7wyrmmERowYwdKlS3n//fdZt24dP/7xj5tMT+nz+fjFL37BDTfcwJNPPsnmzZv54IMPeOSRR5p8zuWXX84dd9yBZVlNRuH3FgqfzTAcDoI5fQAIbN3a8oGxZneFTxERka7icDh45plnWLlyJWPHjuW6667j97//fex9j8fDa6+9Rr9+/Zg9ezbjxo3jjjvuiM05fsopp/D3v/+dl156iaOOOorTTjutyYj0u+66i0GDBnHiiSdy0UUXcf3118f1hMUbb7yRo48+mlmzZnHKKafEAnBjN910Ez//+c+5+eabGT16NOeffz579uxpcsyFF16Iy+XiwgsvbNfk/wc79flsQSAnB29hEYGt2+CkFg6KTbVU02XlEhEREZgxYwZr165tsq9xP80hQ4bw/PPPt3j+2Wefvd9I9agBAwbw6qtNR/yXl5fHtocOHdrs1FDZ2dn7zQ+6L4fDwa9+9St+9atftXhMcXEx9fX1/PCHP2z1s3oqhc8WBHNygLZqPtXsLiIiIh0jGAxSUlLCjTfeyLHHHsvRRx/d3UXqFGp2b0EgrvCp0e4iIiLSMd577z369+/Pxx9/zKJFi7q7OJ1GNZ8tiNV8tvaUI83zKSIiIh3klFNOSfhJTz2Raj5bEK35DO7ahdnoMVdNeNTsLiIiIpIIhc8WhFNTMVJSwLII7tjR/EGq+RQRERFJiMJnSwwDT2Sy+Rb7fUb7fAYUPkVERETiofDZCveQwUAr/T412l1EREQkIQqfrXC3WfOpZncRERGRRCh8tsIzZCiAPdF8czTVkoiIiEhCFD5bEWt2b6nm05Nir0P1YJpdUygRERHhlFNO4dprr+3uYkg7KHy2wj3YbnYP7d2LWdPMIzSjNZ8AIfX7FBEREWmLwmcrnBnpOLOygBYGHbkahU8NOhIRERFpk8JnGzxDhwIthE+HA1w+ezvQTM2oiIiIdLqysjIuueQSsrKySE5O5owzzmDjxo2x97dt28acOXPIysoiJSWFI488kpdffjl27ty5c+nbty9JSUmMGDGCxx57rLu+yiFBj9dsg2fIEOo++6z1Ee+hetV8iohI72BZ8Q+kNU372IDTrpA5EO5kMIx2nfr973+fjRs38tJLL5Gens4vfvELZs+ezdq1a3G73Vx11VUEAgHefvttUlJSWLt2LampqQDcdNNNrF27lv/+97/k5OSwadMm6ur03/TOpPDZhljNZ2vhs65UI95FRKR3CNbCbwfEdagDyOyo6/7ProaBvAmIhs733nuP4447DoCnnnqKQYMG8eKLL/Ld736X7du3c8455zBu3DgADjvssNj527dvZ+LEiUyePBmAoZH/7kvnUbN7GzxDo3N9arolERGRg826detwuVxMnTo1tq9Pnz6MGjWKdevWAfCzn/2M3/zmNxx//PEsXLiQL774InbsT37yE5555hmOOuoobrjhBt5///0u/w6HGtV8tqHNmk+PnnIkIiK9iDvZroWMg2maVFZVkZ6WhqMjmt07yeWXX86sWbNYsmQJr732Grfffjt33XUXV199NWeccQbbtm3j5ZdfZunSpUyfPp2rrrqKP/zhD51WnkOdaj7b4Blsz/UZrqggVFa2/wF6ypGIiPQmhmE3f8e7uJMTO76lpZ39PUePHk0oFOLDDz+M7SspKaGgoIAxY8bE9g0aNIgrr7ySf/7zn/z85z/n4Ycfjr3Xt29fLr30Uv72t79xzz338NBDD7X/5ydtUs1nGxzJybhycwkVFRHctg1XZOqlmGize0DhU0REpKuNGDGCM888kyuuuII///nPpKWl8ctf/pL8/HzOPPNMAK699lrOOOMMRo4cSVlZGW+++SajR48G4Oabb2bSpEkceeSR+P1+/vOf/8Tek86hms84eKLPeG9uuiXVfIqIiHSrxx57jEmTJvGtb32LadOmYVkWL7/8Mm63G4BwOMxVV13F6NGj+cY3vsHIkSN58MEHAfB4PCxYsIDx48dz0kkn4XQ6eeaZZ7rz6/R6qvmMg2foUGo/+gh/c/0+PfZUDdSVdmmZREREDmXLly+PbWdlZfHkk0+2eOx9993X4ns33ngjN954Y0cWTdqgms84RAcdBZur+cwba693fNx1BRIRERHpoRQ+4xCdbqnZms+hJ9jr7SvADHddoURERER6IIXPOMRqPrduw7Kspm/mjQdvOvgrofCL/U8WERERkRiFzzh4Bg4EhwOztpbQ3r1N33Q4YfCx9vbW97q+cCIiIiI9iMJnHAyPB3d+PtBCv88hx9vrbQqfIiIiIq1R+IxTdLql5vt9nmivt72nfp8iIiIirVD4jFOrj9nsP8Gecqm+AorWdGm5RERERHoShc84tTrRvNMFg6ba22p6FxEREWmRwmecWq35hIYpl7a+2yXlEREREemJFD7jFJ3rM7h9B1a4mX6d0fC57T0wzS4smYiIiCRq6NCh3HPPPd1djEOSwmec3AMGgNuNFQgQ3F24/wEDJtrPea8rg73rur6AIiIiIj2AwmecDKcTz6BBAAS2bd3/AKe7od+n5vsUERGRThIOhzF7cCurwmcC2u73GZ3vU/0+RUREOstDDz3EgAED9gtgZ555Jj/4wQ/YvHkzZ555Jrm5uaSmpnLMMcfw+uuvt/t6d999N+PGjSMlJYVBgwbx05/+lOrq6ibHvPfee5xyyikkJyeTlZXFrFmzKCsrA8A0TX73u98xfPhwvF4vgwcP5rbbbgNg+fLlGIZBeXl57LNWrVqFYRhsjeSNxx9/nMzMTF566SXGjBmD1+tl+/btfPzxx8ycOZOcnBwyMjI4+eST+fTTT5uUq7y8nB//+Mfk5ubi8/kYO3Ys//nPf6ipqSE9PZ3nn3++yfEvvvgiKSkpVFVVtfvn1RaFzwTEwmdzI94BhkQHHb0H+z6GU0REpAewLIvaYG3cS12oLqHjW1r2e3x1K7773e9SUlLCm2++GdtXWlrKK6+8wty5c6murmb27NksW7aMzz77jG984xvMmTOH7du3t+tn4nA4+OMf/8iaNWt44okneOONN7jhhhti769atYrp06czZswYVqxYwbvvvsucOXMIR8aILFiwgDvuuIObbrqJtWvXsnjxYnJzcxMqQ21tLXfeeSd/+ctfWLNmDf369aOqqopLL72Ud999lw8++IARI0Ywe/bsWHA0TZMzzjiD9957j7/97W+sXbuWO+64A6fTSUpKChdccAGPPfZYk+s8/vjjnHvuuaSlpbXrZxUPV6d9ci8Um26ppZrP/KPB5YPaYthbAP2O6LrCiYiIdIC6UB1TF0/t8ut+eNGHJLuT4zo2KyuLM844g8WLFzN9+nQAnn/+eXJycjj11FNxOBxMmDAhdvyvf/1rXnjhBV566SXmzZuXcNmuvfba2PbQoUP5zW9+w5VXXsmDDz4IwO9+9zsmT54cew1w5JFHAlBVVcW9997L/fffz6WXXgrA4YcfzgknnJBQGYLBIA8++GCT73Xaaac1Oeahhx4iMzOTt956i29961u8/vrrfPTRR6xbt46RI0cCcNhhh8WOv/zyyznuuOPYvXs3ubm57N27l//+978HVEscD9V8JqDNmk+XFwZNsbfV9C4iItJp5s6dyz/+8Q/8fj8ATz31FBdccAEOh4Pq6mquv/56Ro8eTWZmJqmpqaxbt67dNZ+vv/4606dPJz8/n7S0NC6++GJKSkqora0FGmo+m7Nu3Tr8fn+L78fL4/Ewfvz4JvuKioq44oorGDFiBBkZGaSnp1NdXR37nqtWrWLgwIGx4LmvKVOmcOSRR/LEE08A8NxzzzFkyBBOOumkAyprW1TzmYDYdEtf78QKBjHc7v0PGnICbHnbnu/zmMu7uIQiIiIHJsmVxIcXfRjXsaZpUlVVRVpaGg7HgdVnJbmSEjp+zpw5WJbFkiVLOOaYY3jnnXf4v//7PwCuv/56li5dyh/+8AeGDx9OUlIS5557LoFAIOFybd26lW9961v85Cc/4bbbbiM7O5t3332XH/7whwQCAZKTk0lKarnsrb0HxH5ujbsdBIPBZj/HMIwm+y699FJKSkq49957GTJkCF6vl2nTpsW+Z1vXBrv284EHHuCGG27gqaee4vvf//5+1+loqvlMgKtfP4ykJAiHCXz9dfMHRQcdqd+niIj0QIZhkOxOjntJciUldHxLS6KBx+fzcfbZZ/PUU0/x9NNPM2rUKI4++mjAHvzz/e9/n+985zuMGzeOvLy82OCdRK1cuRLTNLnrrrs49thjGTlyJLt27WpyzPjx41m2bFmz548YMYKkpKQW3+/bty8Au3fvju1btWpVXGV77733+NnPfsbs2bM58sgj8Xq9FBcXNynX119/zYYNG1r8jO9973ts27aN++67j4KCAi655JK4rn0gFD4TYBhGHP0+J4PTCzV7oGRT1xVORETkEDN37lyWLFnCo48+yty5c2P7R4wYwT//+U9WrVrF559/zkUXXdTuqYmGDx9OMBjkvvvu46uvvuKvf/0rixYtanLMggUL+Pjjj/npT3/KF198wfr16/nTn/5EcXExPp+PX/ziF9xwww08+eSTbN68mQ8++IBHHnkk9vmDBg3illtuYePGjSxZsoS77rorrrKNGDGCv/71r6xbt44PP/yQuXPnNqntPPnkkznppJM455xzWLp0KVu2bOG///0vr7zySuyYrKwszj77bG644QZOPfVUBg4c2K6fUyIUPhPUMN1SC/0+3T4YeIy9rUdtioiIdJrTTjuN7OxsCgoKuOiii2L77777brKysjjuuOOYM2cOs2bNitWKJmrChAncfffd3HnnnYwdO5annnqK22+/vckxI0eO5LXXXuPzzz9nypQpTJs2jX/961+4XHbvxptuuomf//zn3HzzzYwePZrzzz+fPXv2AOB2u3n66adZv34948eP58477+Q3v/lNXGV75JFHKCsr4+ijj+biiy/mZz/7Gf369WtyzD/+8Q+OOeYYLrzwQsaMGcMNN9wQG4UfFe1C8L3vfa9dP6NEGVYicxt0k8rKSjIyMqioqCA9Pb3TrxcMBnn55ZeZPXs27n36de75v3so+fOfybzgfPrfckvzH/Dmb+GtO2HsuXDuI51eXmlZa/dSehbdy95D9/LgUV9fz5YtWxg2bBg+ny/h803TpLKykvT09APu8ynd569//SvXXXcda9euJScnp9V72drvTLx5Tb8pCWqz5hOaPuf94M/2IiIicgiqra1l8+bN3HHHHfzoRz/C4/F0yXUVPhMU6/PZ0nRLYDe7Oz1QtRtKv+qikomIiEiinnrqKVJTU5tdonN19la/+93vOOKII8jLy+OXv/xll11XUy0lyDNsKACh3bsx6+pwNDeNgTsJ8ifB9hV2v88+h3dtIUVERCQu3/72t5k6tflJ9Xt7t5BbbrmFWyJdCKNdKLqCwmeCnJmZONLTMSsrCWzfgW9U8xO3MvQEO3xuew8mXdq1hRQREZG4pKWldeqjJGV/anZPkGEYjfp9bm35wCGa71NERERkXwqf7RB90lGr/T4HTQGHCyq/hvJWjhMRERE5hCh8tkObE80DeFJgQGROMc33KSIiIgIofLZLrNm9tZpPaJhyaet7nVsgERERkR5C4bMdPEOGAm3UfELDc963qeZTREREBBQ+2yXa5zNcUkK4qqrlAwdNBcMJ5dvtRUREROQQp/DZDs7UVJw5OUAbTzrypsGAifa2mt5FREQOGkOHDuWee+6J61jDMHjxxRc7tTyHEoXPdoqNeFfTu4iIiEjcFD7bKa7HbAIM0aAjERERkSiFz3aKa6J5gMHHguGAsi1QsbPTyyUiInIgLMvCrK2Nf6mrS+z4FhYrgQeyPPTQQwwYMADTNJvsP/PMM/nBD37A5s2bOfPMM8nNzSU1NZVjjjmG119/vcN+Rl9++SWnnXYaSUlJ9OnThx/96EdUV1fH3l++fDlTpkwhJSWFzMxMjj/+eLZFKqs+//xzTj31VNLS0khPT2fSpEl88sknHVa2nkCP12ynuGs+fenQfwLs+sx+1Ob487qgdCIiIu1j1dVRcPSkhM4p6oDrjvp0JUZyclzHfve73+Xqq6/mzTffZPr06QCUlpbyyiuv8PLLL1NdXc3s2bO57bbb8Hq9PPnkk8yZM4eCggIGDx58QOWsqalh1qxZTJs2jY8//pg9e/Zw+eWXM2/ePB5//HFCoRBnnXUWV1xxBU8//TSBQICPPvoIwzAAmDt3LhMnTuRPf/oTTqeTVatW9fpnyO9L4bOdGtd8WpYV+6Vq1pDj7fC59V2FTxERkQOUlZXFGWecweLFi2Ph8/nnnycnJ4dTTz0Vh8PBhAkTYsf/+te/5oUXXuCll15i3rx5B3TtxYsXU19fz5NPPklKSgoA999/P3PmzOHOO+/E7XZTUVHBt771LQ4//HAARo8eHTt/+/bt/L//9/844ogjABgxYsQBlacnUvhsJ0/kfzmZVVWEy8pwZWe3fPDQE2HF/XrSkYiIHPSMpCRGfboyrmNN06Syqor0tDQcjgPryWckJSV0/Ny5c7niiit48MEH8Xq9PPXUU1xwwQU4HA6qq6u55ZZbWLJkCbt37yYUClFXV8f27Qc+7eG6deuYMGFCLHgCHH/88ZimSUFBASeddBLf//73mTVrFjNnzmTGjBmcd9559O/fH4D58+dz+eWX89e//pUZM2bw3e9+NxZSDxXq89lODp8P1wD7Fymufp8YULoZqgo7vWwiIiLtZRgGjuTk+JekpMSOb2FptQWxGXPmzMGyLJYsWcKOHTt45513mDt3LgDXX389L7zwAr/97W955513WLVqFePGjSMQCHTGj2w/jz32GCtWrOC4447j2WefZeTIkXzwwQcA3HLLLaxZs4ZvfvObvPHGG4wZM4YXXnihS8p1sFD4PADeWNN7G/0+kzIhb5y9rdpPERGRA+bz+Tj77LN56qmnePrppxk1ahRHH300AO+99x7f//73+c53vsO4cePIy8tja1sVRXEaPXo0n3/+OTU1NbF97733Hg6Hg1GjRsX2TZw4kQULFvD+++8zduxYFi9eHHtv5MiRXHfddbz22mucffbZPPbYYx1Stp6iXeHzgQceYOjQofh8PqZOncpHH30U13nPPPMMhmFw1llnteeyBx33kDjn+oSG57xv05RLIiIiHWHu3LksWbKERx99NFbrCXY/yn/+85+sWrWKzz//nIsuumi/kfEHck2fz8ell17K6tWrefPNN7n66qu5+OKLyc3NZcuWLSxYsIAVK1awbds2XnvtNTZu3Mjo0aOpq6tj3rx5LF++nG3btvHee+/x8ccfN+kTeihIOHw+++yzzJ8/n4ULF/Lpp58yYcIEZs2axZ49e1o9b+vWrVx//fWceOKJ7S7swSZW89nWiHdoCJ+q+RQREekQp512GtnZ2RQUFHDRRRfF9t99991kZWVx3HHHMWfOHGbNmhWrFT1QycnJvPrqq5SWlnLMMcdw7rnnMn36dO6///7Y++vXr+ecc85h5MiR/OhHP+Kqq67ixz/+MU6nk5KSEi655BJGjhzJeeedxxlnnMGtt97aIWXrKRIecHT33XdzxRVXcNlllwGwaNGi2P/q+OUvf9nsOeFwmLlz53LrrbfyzjvvUF5efkCFPlgkVPM5eBpgQPEGqN4Dqf06tWwiIiK9ncPhYNeuXfvtHzp0KG+88UaTfVdddVWT14k0w+87B+m4ceP2+/yo3NzcFvtwejwenn766biv21slFD4DgQArV65kwYIFsX0Oh4MZM2awYsWKFs/73//9X/r168cPf/hD3nnnnTav4/f78fv9sdeVlZUABINBgsFgIkVul+g12rqWY+BAAALbtxHw+zFaG+nnTsPVbwzGnjWEvnoba/SZHVZeaVm891IOfrqXvYfu5cEjGAzak8qbZruapaOhLPoZ0nPFey9N08SyLILBIE6ns8l78f5NJxQ+i4uLCYfD5ObmNtmfm5vL+vXrmz3n3Xff5ZFHHmHVqlVxX+f2229vtgr6tddeIznOCWg7wtKlS1s/IBxmhMMBdfUsfeZZQpkZrR4+1srncNaw/e2n+XLLoTWhbHdr815Kj6F72XvoXnY/l8tFXl4e1dXVBzQSvKqqqgNL1bWee+455s+f3+x7gwYNarVyrTdq614GAgHq6up4++23CYVCTd6rra2N6xqdOs9nVVUVF198MQ8//DA5OTlxn7dgwYImvwiVlZUMGjSI008/nfT09M4oahPBYJClS5cyc+bMNp86sO3PDxHcto0TDj+M5KlTWz3WWG/CP15jmLWNQWecAQlOKyGJS+ReysFN97L30L08eNTX17Njxw5SU1Px+XwJn29ZFlVVVaSlpSU8VdLB4vzzz+eUU05p9j23290lueNgEO+9rK+vJykpiZNOOmm/35loS3VbEgqfOTk5OJ1OioqaPkirqKiIvLy8/Y7fvHkzW7duZc6cObF90apcl8tFQUFBsxOrer1evF7vfvvdbneX/kMVz/U8Q4cQ3LaN8Fdf4T7hhNY/8PCTwZWEUbIRd8FLMO7cDiyttKarf3ek8+he9h66l90vHA7b83o6HO2aJD763/ToZ/REGRkZZGS03nJ5KIj3XjocDgzDaPbvN96/54R+UzweD5MmTWLZsmVNCrts2TKmTZu23/FHHHEEX375JatWrYot3/72tzn11FNZtWoVgwYNSuTyB6WUyPcue2oxVjjc+sHJ2XBipEb3tZvAX93JpRMREWnbvgNqRFrSEb8rCf/PlPnz5/Pwww/zxBNPsG7dOn7yk59QU1MTG/1+ySWXxAYk+Xw+xo4d22TJzMwkLS2NsWPH4vF4DvgLdLes734XR0YGgW3bqHrttbZPOO5nkDUUqnbBO3/o9PKJiIi0JFpTFW9fPZHo78qBtFok3Ofz/PPPZ+/evdx8880UFhZy1FFH8corr8QGIW3fvr3HVr23hyMlheyLL6b4/vsp/vNDpH3jG633e3H7YNbt8MyF8P79cNT3IGd41xVYREQkwul0kpmZGZurOznBx1yapkkgEKC+vv6Q+m9/b9TWvbQsi9raWvbs2UNmZuZ+I90T0a4BR/PmzWPevHnNvrd8+fJWz3388cfbc8mDWvb35lL66KP416+nevly0k49tfUTRp0Bw2fCpqXwyi9h7t81+EhERLpFdMxGWw+LaY5lWdTV1ZGUlNRjBxyJLd57mZmZ2ew4n0R06mj3Q4UzM5Osiy6k5C+PULLoz6Seckrrf4SGAd+4Ax5cbgfQDa/YgVRERKSLGYZB//796devX8JzrwaDQd5++21OOukkDR7r4eK5l263+4BqPKMUPjtI9qWXUvrkX6n7/HNqP/yIlGNbn3aJnOFw3Dx49//s2s/DTrWb5EVERLqB0+lMOFg4nU5CoRA+n0/hs4frynupDhodxNW3L5nn2lMnlTz05/hOOvF6SBsAZVvh/fs6r3AiIiIiBwmFzw7U54c/AJeLmvdXUPfFF22f4E2F039tb79zF5Rv79wCioiIiHQzhc8O5M7PJyMyoX7xnx+K76Sx58CQEyBUB6/d2ImlExEREel+Cp8drM8VV4BhUL1sGfUFG9o+wTDgjDvBcMLaf8FXyzu9jCIiIiLdReGzg3kPG0barFkAlDwUZ+1n3lg45nJ7++UbIJzYaEMRERGRnkLhsxPk/PhHAFT+978Etm2L76RT/weSc6C4AD6Mc8CSiIiISA+j8NkJfKNHk3LySWCalPzlL/GdlJQJMxba28vvgKqiTiufiIiISHdR+OwkOT++EoDyF/9FsLAwvpOO+h4MOBoCVfD6wk4snYiIiEj3UPjsJMlHTyT5mGMgGKTk0UfjO8nhgNl/sLc/fxq2f9h5BRQRERHpBgqfnajPlT8GoPy5vxMqKYnvpIGTYOL37O2Xrwcz3EmlExEREel6Cp+dKOW44/CNHYtVX0/pk3+N/8Tpt4A3Awq/gE+f6LTyiYiIiHQ1hc9OZBgGOZHaz7KnniJcWRnfial97dHvAMv+F2pLO6mEIiIiIl1L4bOTpZ52Gt4RwzGrqylb/HT8Jx5zOfQbA3VlsPg8qI8zuIqIiIgcxBQ+O5nhcNDnR/a8n6VPPIFZWxvfiU4XnP0Q+DLh64/hb2crgIqIiEiPp/DZBdLPOAP3oEGEy8oof/75+E/MGweXvqQAKiIiIr2GwmcXMFwu+lxuPz6z5JFHMQOB+E/uP0EBVERERHoNhc8ukvGds3D160eoqIiKF19M7GQFUBEREeklFD67iMPjIfsHlwFQ/OCfCBYl+PhMBVARERHpBRQ+u1DWeefhHjKYUGEh2y/7AaHSBKdQUgAVERGRHk7hsws5kpMZ8uijuPLyCHz1Fdt/eHn8c39GKYCKiIhID6bw2cXc+fkMfuxRnDk5+NetY8cVP8KsqUnsQxRARUREpIdS+OwG3mHDGPzIIzgyMqj7/HN2/PQqzPr6xD5EAVRERER6IIXPbuIbNZLBf3kYR0oKtR9+yM5rrsVKZAomUAAVERGRHkfhsxsljRvHoEV/wvD5qH7rLXbe8AusUCixD9k3gD7xLSjZ3CnlFRERETlQCp/dLPmYYxh4330YbjdVr7zC7htvwjLNxD4kGkCTsmH35/Dnk2DV02BZnVNoERERkXZS+DwIpJ54AgPuvgucTipefJGi39yGlWhw7D8BrnwHhpwAgWp48Ur45xVQX9E5hRYRERFpB4XPg0T6zJkMuON2MAzKFi9m7113JR5AMwbaNaCn3QiGE778Oyw6AXZ81DmFFhEREUmQwudBJGPOHPJuuQWAkr88QsmiRYl/iMMJJ/0/+MGrkDkEyrfDo9+At34HZrhjCywiIiKSIIXPg0zW+efR75e/AGDvvX+k9Ikn2vdBg46xm+HHfResMLx5Gzz+LSjf0YGlFREREUmMwudBqM/3v0/O1fMAKLr9Dvb84Q+YiU7DBODLgHP+At95CDypsP19WHQ8rHmxYwssIiIiEieFz4NUzk9/Sp8rrgDsJvit55xL/bp17fuwCefbtaD5k+wBSH+/FF66GgIJPllJRERE5AApfB6kDMOg38/nM/CB+3H26YN/40a2fPc8ihctSnwuUIDsw+x+oCf+HDDg0yfhzyfD1nc7vOwiIiIiLVH4PMilTZ/OYf9+ibSZMyEUYu8997J17lz8X21J/MOcbph+sz0iPm0AlGyEx78Jz34PStvxeSIiIiIJUvjsAVzZ2eT/8V4G/O5OHGlp1H/+BVvOPpvSJ/+a+IT0AMNOgp+8B8dcDoYD1v0bHpgCS2/W4zlFRESkUyl89hCGYZDx7W9z2L9fIuW447Dq6yn67W/Z/oMfEty5M/EPTM6Gb94FV74Hh50K4QC8dy/cdzSsfFzTMomIiEinUPjsYdx5eQx65C/kLbwZIymJ2g8+4Ktvn0n5P/6Z+KT0ALlj4OIX4KLnoM8IqNkL/77GfkTnV291/BcQERGRQ5rCZw9kGAZZF17IYS++QNLEiZg1Nez+1a/4+qp5hPbubc8HwshZ8NMV8I07wZcJRavhyW/D0xdByeYO/w4iIiJyaFL47ME8Q4Yw5G9/pe/P52O43VS/8QabZ32DPXfdTai0NPEPdLrh2CvhZ5/BlB/bj+gsWAIPTIVXfwV15R3+HUREROTQovDZwxlOJzlXXMHQ55/Hd+SRmLW1lDz8MJtmzKTo978nVFyc+IcmZ8Ps39k1ocNnghmEFffDPePgtRuh4uuO/yIiIiJySFD47CV8o0Yy9Pm/M/DBB/AdeSRWbS2ljzxqh9Db7yC4Z0/iH9p3FHzveZj7D+g7GvyV8P59cO8E+OePYPcXHf9FREREpFdT+OxFDMMg7bTT7BC66E/4xo/Hqq+n9Ikn2DzzdApv+y3BoqLEP3jEDPjJ+3DhszD0RDBD8MWz8OcT4Ylvw8bXoT2DnUREROSQo/DZCxmGQdoppzD02WcY9PDDJB11FJbfT9lf/8rmGTMp/N//Jbh7d2If6nDAqG/A9/8DP1oOY8+1+4RueQueOgcenAaf/Q1C/k75TiIiItI7KHz2YoZhkHriCQx5ejGDH32EpEmTsIJByhY/zabTZ7H75oUEtm1L/IMHTIRzH4FrVsG0eeBJhb3r4F9X2f1C3/4D1LZjwJOIiIj0egqfhwDDMEg57jiG/O2vDH78cZKnTIFgkPLnnmPzN85gx7x51K5cmfg8oZmDYdZtcN0amPm/9iM7q4vgjV/D/x0JL/0Mdq3qlO8kIiIiPZPC5yHEMAxSjp3KkCefYMhfnyTl5JPAsqh+fRnb5n6PredfQOXLL2OFQol9cFImHH8NXPM5fOchyB0HwVr49Al46GR46FS7ST5Q2ynfS0RERHoOhc9DVPIxxzD4z3/msP/8m8zvnovh8VD/xRfsnP9zNp8+i5LHHydcXZ3Yh7o8MOF8uPId+P7Ldr9Qhxt2fWo3yd91BPz3F7C3oHO+lIiIiBz0FD4Pcd7hw+n/618z/M03yLnqKpxZWQR37WLPHXey6ZRTKbrzdwR37UrsQw0Dhh5v9wudvw5m3AKZQ8BfAR8uggemwGPfhC+fh1CgU76XiIiIHJwUPgUAV58+9L16HsPffIO8/70Vz2GHYVZXU/rYY2yaeTo7f349tR9/nHiTfGpfOOE6+Nkq+N4/YNQ3wXDAtnfhHz+E/xsDr98CpV91xtcSERGRg4yruwsgBxeHz0fWeeeRee65VL/9NqWPP0HtBx9QuWQJlUuW4MjIIPXEE0k9+WRSTzwBZ2ZmnB/sgOEz7KViJ3z6pN0ntGo3vPt/9pI/GcZ9F478DqTldur3FBERke6h8CnNMhwO0k45hbRTTqF+7VpK//o3qt94g3BFBZX/+Q+V//kPOBwkTZxI6iknk3ryyXhHjMAwjLY/PCMfTl0AJ10PG16BTx6Fr5bDzk/s5dUF9mT2474Lo+fYA5pERESkV1D4lDb5xoxhwO2/xQqFqPv8c6qXv0X18uX4N26kbuVK6lauZO9dd+MeMMAOoqecQvKUKTh8vtY/2Om2w+XoOVBVBGtegNXPw9cf25PXb3kLlsyHEafD2HNg5DfAk9w1X1pEREQ6hcKnxM1wuUieNInkSZPo9/P5BHfupOqtt6h+6y1qP/iQ4K5dlC1+mrLFT2P4fKQceyypJ59E6kkn4c7Pb/3D03Lh2CvtpXQLrP6HPSBp7zpY/x978aTCEd+0R9Efdoo9ul5ERER6FIVPaTd3fj7ZF11E9kUXYdbVUfPBB3at6FtvESospHr5cqqXLwfAO2I4KSedROrJJ5M8cSKG293yB2cPs5vkT7oeitbYIfTL56Fiu/1M+S+eBU+a/cz5Ud+EETPVNC8iItJDKHxKh3AkJZF26qmknXoqlmXhLyig+u13qH7rLeo++wz/xk34N26i9JFHcaSmknL88bFBS66+fVv+4Nwj7WX6zXZz/Jd/h7X/sp+ktOYFe3G4YMjxdq3oqNmQOajrvriIiIgkROFTOpxhGPiOOALfEUeQ86MrCFdUUPPee1S/9RbVb79DuKyMqldfperVVwHwHXkkqaeeStrMmXhHtjBoyTBg0BR7+cad9sT165dAwcuwd31DH9H/3gB54+wa0SNmQ5/RXfztRUREpDUKn9LpnBkZpM+eTfrs2VjhMPWrV1P91ttUv/029atXU79mDfVr1lB8//24hwwm/fTTSZs5E9+4cc0HUYcDBk62lxkLoWSzHULXL4EdH0Lhl/by1h240gcyznMExiYPDD8F3Eld/v1FRESkgcKndCnD6SRpwgSSJkyg78+uJlRcTPVbb1O1bBk1775LcNt2Sh7+CyUP/wVXXh5pM2aQNnMmyZMnYTidzX9on8PhuKvtpabYnr5p/cuw+Q2Myq85jK/h2dfBlQTDTrL7iI6cBZmDu/bLi4iIiMKndC9XTg6Z55xN5jlnY9bUUP3221QtXUr1cnvQUtnf/kbZ3/6GMzubtOmn2UH02GNxeFoY6Z6SAxO/Zy+BWkIbX2fHG48yNFCAUbULNr5qLy9fD32PsKdxGnE6DD7WnvpJREREOpXCpxw0HCkppJ9xBulnnIHp91Pz/vtUvbbUnty+tJTyvz9P+d+fx5GaSvLUqaQceywp047Fc/jhzTfPe5KxRp7BF5ssBp5xBu7SDbDxNXvZ8aHdV3Tvenj/j+BNh8NPtYPoYadAxsAu//4iIiKHAoVPOSg5vN6G0fPBILWffELV0qVULX2d0N69VC9bRvWyZQC4+vYledqxpBw7jZRpx+Lu33//DzQMyBtrLyfOh7oy2LQMNi6FTUuhtsQeRb/2X/bx2YfbTfTDToShJ9nPqBcREZEDpvApBz3D7SZl2jRSpk0j98YbqV+zhpoVH1D7wQpqV35KaO9eKl/6N5Uv/RsAz9ChpBw3jeRjj8Vz9KTmPzQpC8aday9mGHZ9BhtehU2vw+5VULrZXlY+Zh/fb0wkjJ5kT+ukeUVFRETaReFTehTD4SBp3DiSxo2DH12B6fdT99ln1Kz4gJoPVlD/5WoCW7cS2LqVssVPg2EwJLcfhW+/Q/KY0XhHjsJ3xKimc4s6nA2j50/7FdRXwLb3Ycvb9lK0GvastZcPF4HhgP4T7CA69EQYNBV86d33QxEREelBFD6lR3N4vXbfz2OPBa4lXFlJ7ccf22F0xQoCmzfjLSyieskSqpcsiZ3n7NMH36hReEfZYdR7xBF4hw3D8HjAlwGjzrAXsEfQb32nIYyWbLJrSnd9Bu/d2xBGhxxvL4OPheTs7vmBiIiIHOQUPqVXcaankzZ9OmnTpwNQt2sX7z35JOPS0ghu2oR/fQGBrVsJl5RQ8/771Lz/fsPJbjfeww8n+eiJJB9zDMmTJ9s1pCk5cOR37AWgYmdDGN36LpRvawijK+4HDPupTEOOiwTS4yC1X9f/MERERA5C7QqfDzzwAL///e8pLCxkwoQJ3HfffUyZMqXZYx9++GGefPJJVq9eDcCkSZP47W9/2+LxIh3J1bcvNaNHkz17Nu7I8+TNujr8GzdSX1CAf30B9QXr8RdswKyqwr9+Pf716+0me+z+o8nHHEPyMZNJPuYYezBTRj5MuMBeACq+tpvpt71nr4s32E31Ravho4fsY3JG2iF00LEweCpkDbMHQYmIiBxiEg6fzz77LPPnz2fRokVMnTqVe+65h1mzZlFQUEC/fvvX7ixfvpwLL7yQ4447Dp/Px5133snpp5/OmjVryM/P75AvIZIIR1ISSePHkzR+fGyfZVmEdu2ibvUaaj/5hNqPP8ZfUBDrP1r+978D4M7Pj4RRO5C6Bw3CyBgI48+zF4DqPU3DaNFqO5AWb4CVj9vHpPSzHxU6+Fg7kPYfDy5vF/8kREREul7C4fPuu+/miiuu4LLLLgNg0aJFLFmyhEcffZRf/vKX+x3/1FNPNXn9l7/8hX/84x8sW7aMSy65pJ3FFulYhmHgzs/HnZ9P+qzTAQhXVFC78lNqP/6Y2k8+oX7tWoI7d1KxcycVL74IgDM72+4zOnIU3iNG4Rs1Cs/hh+M48iw48iz7w2tLYfsHdhjd8ZHdPF+zB9b/x14AnF7IP9oevBRdUvp0+c9BRESksyUUPgOBACtXrmTBggWxfQ6HgxkzZrBixYq4PqO2tpZgMEh2dssDMvx+P36/P/a6srISgGAwSDAYTKTI7RK9RldcSzrXAd3L5GR8J56A78QTyAbMmhrqVq2i/pNPqPtkJfWrVxMuLaXm/RXUvN/o99/lwjN0KJ5Ro/COHBFZH4Xz1Bn2ZPiheozdqzC+/ghjx0f2uq4Utq+wlwgr+3Cs/MlYAyZh5k+yp3s6hJ/CpL/L3kP3svfQvew9OuJexnuuYVmWFe+H7tq1i/z8fN5//32mTZsW23/DDTfw1ltv8eGHH7b5GT/96U959dVXWbNmDT6fr9ljbrnlFm699db99i9evJjk5OR4iyvSqYxgEE9hId7du/HujqwLd+Osq2/2+FBKCv7+/Qnk5eHvn2dv9+uH5XKR6i8ku2ajvVRvIM2/e//zDQ/lycMoSzncXpIPp96jUfUiInJwqK2t5aKLLqKiooL09JanIOzS0e533HEHzzzzDMuXL28xeAIsWLCA+fPnx15XVlYyaNAgTj/99Fa/TEcJBoMsXbqUmTNnxgapSM/U1ffSsixCRUUECgrwb9hAoGAD/g0bCG7bhqumBtemTaRs2tRwgtNp15KOHIl35Eg8Y76Ja+QIAmluHLs/w9j5CcaulRg7V+LyV5JTU0BOTUHD9dIG2LWj+Udj5Y3Hyh1nT6DfC+nvsvfQvew9dC97j464l9GW6rYkFD5zcnJwOp0UFRU12V9UVEReXl6r5/7hD3/gjjvu4PXXX2d8o4EezfF6vXi9+w++cLvdXfrL3dXXk87TlffSM2gQyYMGwYwZsX1mXR3+TZvwb9hA/foC/AUF1BcUYFZUENi8mcDmzVT/97+x450ZGbiHDMHVpw/OPmNxZZ+MK9PEZZXgDHyNq2YDrpoNOCp34ah6Cda/1FCAjMGQN84exJQ33t7OGNhrRtfr77L30L3sPXQve48DuZfxnpdQ+PR4PEyaNIlly5Zx1llnAWCaJsuWLWPevHktnve73/2O2267jVdffZXJkycnckmRXsGRlNTwZKYIy7II7dmDf/166gs24C8owL+hAP9XWwhXVBD+4os2PjUXnA5caT5cyeBNq8OXWoYvaze+kh04Chom1ScpqyGI9p9gL32G2093EhER6UIJN7vPnz+fSy+9lMmTJzNlyhTuueceampqYqPfL7nkEvLz87n99tsBuPPOO7n55ptZvHgxQ4cOpbCwEIDU1FRSU1M78KuI9CyGYeDOzcWdm0vqySfH9pt+P4HNmwnu3k2ouIRQSTHhklJCJSWEi4sJlZQQKinBrKyEsEmovJZQOdQDFWRGPxxvvyR8WSF8ySX4MmvwVr6Nc8tbDQVwp9ghdMBEGHCUvc4+HByOLvwpiIjIoSbh8Hn++eezd+9ebr75ZgoLCznqqKN45ZVXyM3NBWD79u04Gv3H609/+hOBQIBzzz23yecsXLiQW2655cBKL9ILObxefGPG4BszptXjzECAcEkJoeISgrt34V+/nro1a6hfs5ZwcTH+olr8RVBBGpAGBnhyUvDlWPiSSvCk1OIt+xD3tvcbWuQ9aZFAelQklE60J8RXIBURkQ7SrgFH8+bNa7GZffny5U1eb926tT2XEJE2ODweHP374+7fn6RxY+H002PvBYv2UL/WDqL1a+0lVFhIYG8Ngb1QSRKQBIDhduDJcuJNqcab5sf71Sd4M1bgTgljOABvuj3NU+4Yex3d7qUDm0REpHPp2e4ivZA7tx/u3H6knXpqbF+ouJj6deuoX7MG/4aN+DdvJvDVV1jBIP49Jn68QMNAP8MJnrQQ3vQA3ozVeDNW4c0INoTStAHQb3QklB5pb/cdBe6krv/CIiLSYyh8ihwiXDk5pJ54IqknnhjbZ4VCBL/+Gv/mzfg3bca/eRP+TZsIbP4Ky+/HX+7CX970nwnDBd60AN6MWrwZH+DNeBdvRhBXsonhcNj9RnOPhNyxkfWRkDm414y2FxGRA6PwKXIIM6JPYxo6lLTp02P7rXCY4K5d9vRQmzYR2LSJ+o0bCWzajBUIUF/mob7M0+SzHG4Lb3oQT9peXEnLcCUtxZUUxp0UxpWRjGvIERgDxjYE036jwdf58/aKiMjBReFTRPZjOJ14Bg3CM2hQk6Z7KxwmsH27HUo3bowtga3bMIMh6ko81JV4WvjUHTi9W3ElvYQrKWwH06xU3PkD8Aw7HM8R43AOnYCRMxJS+6mmVESkl1L4FJG4GU4n3mHD8A4bBjNnxvZbgQD+rVvxb9xIcOcuQnv2NFmCe/ZAKETY7yTsd+Ivj05EbMHKncBO4G0cHhNPaghPpgNPbiaewQPxHD4Kz+iJkH8khhnqjq8tIiIdSOFTRA6Y4fHgGzkS38iRzb5vmSbhigpCRUUNgXTnNkJbCwhs20Zg5x5CFfWYAQf1pR7qS4GvqmHFemA98C+c3jDjUkwK/3wzruwsXP1ycQ0YgnPwSNyHjcM5YCiuvjk4mnk6moiIHDwUPkWk0xkOB66sLFxZWXDEEc0eY9bVEdi+ncDmjQTWryKwqYDAjh0ECksJVwVjtaaUmrC1BCgB1gL/bfI5jiQ3rsw0XP364uo/CHf+EFy5ubjy7An9Xbm5uHJyMFz6509EpDvoX18ROSg4kpLwjRqFb9QomP2tJu+Fq2uo3bSJz156liMzvZi7thIq2mU/Aaq8mnBNmFC9E8s0MOuCBOpKCewuhc8LWriYgSs7G1def1y5ubhz++Hq3x/PoMF4hgzGPWgwztSULvjWIiKHHoVPETnoOVNT8B05hrJtU0mfPRu32930gLpyrL0FmNu+ILRlNaEdmwjt2k6ouIxgnUGo1kmozkmwzkGozgkmdnAtLoHVq5u/ZnY2nkGDcA8eHFkPwhPZdubkYGhAlIhIuyh8ikjPl5SJMXgqzsFTcZ7YaKr8UADKt0HJZijZBCWbsEo2Ef56M8E9ewnVOQjVOgnWOQnWOAlWuwhU28374dJS6kpLqfv88/0uZyQl4e7XD1ffvrj69bOXZrZVeyoisj+FTxHpvVweyBlhLxEG9j98rkAtlH4VC6WUfhV5vZlw+W6C1U4C1S4C1S6CVfZ2sNoOqlZdnT1Qatu2Vi/vSE7G1bcvzuxsHKmpONNScaSmtb6dkY47Lw9j39pdEZFeQuFTRA5NnmTIG2sv+3D6q3CWbsFXujkSSL+KhVOrYjfBfZrxQ/VOuxY1tu3CDIJZW2sH1DZC6v4FcOLOz8czZEjDMtReuwcM0GApEenR9C+YiMi+vGnQf7y97MPwV+Mp24KnbCvst2wDMwiAGTQI1TsI1jkJ+x2YQQMz6CBs+jAd6ZikEDa9mGE3ZgDC/jBmXYBwRSWW309w+3aC27dT8847TQvgduOJBtOhQ3D1y8WRloozNRVHdElJxZmaEtlOUVgVkYOK/kUSEUmENxXyxtnLvswwVO6Csq04yrbiKduKp2wLlG+3l+oioAZ7mqjmWe40Qu6BBEI5BOpSCFQ7CZQGCBZVENi9B8sfILB1K4GtW+Gt+IpsJCfjTEmJNOtn2EtmJs5Me+3IyMAVWTszM3FmZNr7U5I1sEpEOpzCp4hIR3E4IXOQvQw7cf/3g3VQ8bU9CCoaSBsv1UUYwSrcwXW4gRQnkBFZhoFlQSicQcDMI+DPIFDjJex3EQ45MANg+sOEa+sxa2owq6ux/H4ArNpaQrW1sHdvQl/H8PnsuVHz8nDn5UXWTV87MzMVUEUkIQqfIiJdxZ203wCoJoJ1UL4jEkb3D6hGzR7crgrcVJDiAdKau0YyZAyEjMOwUvMJe/thunIwXVmESSMcdBGurMSsqCBcXk44ui6Pru3FCgax6uvbHFgVC6i5uTj7ZOPKysaZlYUz236ogDM78jorC1dmJobH0yE/ShHpuRQ+RUQOFu4k6DvSXpoTqI3UnEbD6TY7rFbssNfVhRCsheINULwhNrK/CcMBqbmQPgAG9ocx+ZB+OKTn2/vSB2Cl9ccKmoSKiwkWFhIqLCRYWBRZF8bW4dLSuAJqY460NJyZmQwOh9jx17/hcLsxXC4MtwtcLgxX5HXjfR4Prr59cefm4e6fF6t5dSQnH8hPW0S6icKniEhP4UluPZyG/HY4jYbRxuuKHVCx0x4QVbXbXlpgAEZyDp70AXiiofSIATBlOKSfFAmq/TEtF6E9ewju3k2oaA/hslJCZWWES8sIl5URLi0lVB55XV4OpolZVYVZVYUP8O9quQzxcKSnR5r/c3Hn9W9Y98nGkZamgVciByn9JYqI9BYuL/Q53F6aY5pQWwyVO+2BUZW7mt8O1dvH1RZD4RctXs7hy8STno8nUmPK4AEwdgCkHRmpRe0PvkwwDCzTtJv4y8rx793Dh2+9xTETJ+KwLAiFsEIhrGBkHQpCONzw2l9PcM8eQrsLCRYVEtpdaPdrrazEX1mJf8OGuH48RlISjtQUnCmRWQGiswSkpeNMT8eZkY4jPR1negbODHufo9G25l4V6RgKnyIihwqHA1L72cuAic0fY1lQVxYJortbCKo7IVAN9eX2smdNy9d0J0P6AIy0/rjS83Gl98eVkkd6bjWpI9NxZQ22y+NwJvRVwtXVhHbvJlhYRLBwN6Hoeneh3W+1phqzep+BV3V1hOvqCO8tTuhaUUZy8n4zBUQXV6Pt2JKRgSM1VTWuIvvQX4SIiDQwDEjOtpfmppOKqq/cP5BGQ2pVJLTWldl9UKNPkYpwAlMBttwbuWakH2paf7vGNK2/XWuaNqBhndoPfBl2+QBnairOESPwjmhh8FYjViBAuKYmNguAWV1NuDoSTqsqCVdWEa6swKysJFxRSbiy0n5dXmEPzqqutj8nMmtAaHdi3QUMjwdHSgqO5GR7iW6nJONITomskyPztKbZT7xKiz79Ks3uJxuZw1VBVnoD/RaLiEjifOn20u+Ilo8J1u0fSCt3YZZ/TcXX68l01GLU7AHLbOiHuuvTlj/P6Y2E1Fx7ndpvn3WjbZc3dprh8eDyeCArq11f1QqH7RBaWdlodoDml1BsuwKrttY+PxAgHAgQLitr1/UbM5KTI10F0hrCbGxJwpGcjJGcjCNpn/dSU3FmNdTQGsmaw1W6j8KniIh0DndSs31Qw8Egb7/8MrNnz8btdED1HqjaZTfzV+2OhNXCpvv8lRD2Q8V2e2mLL3OfoNpoabwvKStWm9oSw+nElZWVcHg1AwHMmhqs2lrM6FJT07AdfV0T3V9DuKraDrnV1ZhVVYSrqzCrqrHq64FGc7bu2ZNQWfb7Th5PQ/eArKxG2/ZDBozoLAQuJzhdjbadkRkJnBguFyHAt2MHwR07cOTk2LWzDscBlU16P4VPERHpPg6n3bSe3h/yWzkuWGeH1OqiRsue5tfhQEN/1OKC1q/v9EBKv2ZqUfetTe0HnpTEvprHg+MAalwbi3UdqKoiXFmFWV2FWVtnB9i62kYBN7ovsq6NhN3KKrtGtqzMnsM1ECC0Zw+hAwyxAIOBbfc/YL9wOu3BW5E+r437vzqzMnGkpmGFglj1fkx/PVa9H8tfj1lXb6/r/Vj19Zh+e214vZEHG/S3Zzbon4c7rz/u/nk4s7MVdHsohU8RETn4uZMga4i9tCY6YGrfoFpVGNlX2PBeXZkdVCu/tpe2eFIhpW+jpU/DdnIOpESXvpDcB5wdNzr+QLsORFmWhVVb29BFoKxRt4GystiDB2KzDoTCWOHwPtshe4aCcBgzGKS2pARPIIBVVwfhsP05HdDFIKquhf2G240rNzcSSvvjzsvFmZUdC7pNAnBGhvrLHkR0J0REpPdoPGCqtf6oYM+LWl0E1Xub1qbW7FOTWlUEoTp7hH+gGsq2xFeWpKxGQTXHrmGNbqf2axpkvWltNv93BMMwMFJScKSk4M5vrao5PsFgkJcjXSicpmk/KauiUaBt3Ee2ogKzsspu0vd5cXh9GD4fDl907cXwNqwNnxervp7g7kJChbsJ7o485GD3bkLFxVjBIMGvvyb4dRz/wwHsfq+NZyJISYl1L8DtimxHH3rQ8PADw+22F68PR3KSXdakZBxJPnv6rshi+Hx2n1uPR/1p26DwKSIihyaXFzIH20trLMsOnVVFULPXnv+0Zi/UFEeWvQ2va4uhtsQeRFVXZi/FccxD6vRGakyz7VrTlBx7ve8S3Z+UDc6D6z/hDq8XR24/3Ln9Ov1aViBAaO9egoWFDeG0sKiFwFsJEJvpIN6w2m4Ohx1II4O9jJTGg79SmhkolhwJ414MrxfD47VnSPB67Nfe6Gt72+GzQ29P7nJwcP3mioiIHGwMw66Z9KZBzvC2jzfDduiMhdK9du1qTTNL9V4I1tiDqeJt/o/ar2a1ue3I68hk/72F4fHgzs+Pq/bWCoXs6bPKI6G0wp6NwKytafSAg2CThxxYwaD9XjD6XtDuo1pbh1lfj1lXh1VXZ/etjWxbwaB9QdOMDCSr6cQfgGEH3EgtdotLcjJJE8aTeuKJnVeWdlD4FBER6UgOZ0P/T0a3fXygJlKjWgI1JfY6thRDbWnkvUital0ZYCVWs+pw2WE1KcuuNU3Ojqyb2Rc7Lsvua9vDQ6vhcuHKzsaVnd2p17FCITuY1tbawbTJrAa1TV9HB4JFZj+wAkEsvx/L78cM+LH8gUavG7atQCByMSv2Wezd22q5Mi+8QOFTREREGvGk2EvW0PiOj9Ws7tPk36RWtVHXAH8FmKGG9xLh9EJSZkMY9TXaTsrE4Uknv2wbxpYUSOvX0D3A7Uvwh9DzGS6X/fCD1NROu4ZlmnYgjT40IbKEI1N6hZvst8Nt8uTJnVae9lL4FBER6Uma1Ky2MagKIFgPdaV2DWpdWaPtRvv2fa++3A6sYX/DYKxmOIHJAFsfbPqGOyUSRLOb6bu6b4iNLN50+xGw0iLD4YgNciInp7uL024KnyIiIr2Z2wfuAfajS+MVHWRVVwZ15Q1N/PWNtuvKMWtKKNm5mZwkMOoi3QPMkN2PtaImvgcCRBkO+xGqjQOpL9OuefVlRt7LbLQvo2Hbk6bg2oMofIqIiEhTjQdZtTIbQDgY5P3o06rcbju0+isj/VVLG/quRvur1pZEAmx5oxBbBsHapjMEJFzeZoJrtC/rfvuy7BpZX4Zd2+rytPvHJO2j8CkiIiIdwzAiNZIZkH1Y/OeF/PsH0lhNa3nkiVUVDduN94XqDyy4unx2CPWlRwJ3dDsjso68blzT2njtSenxg7K6msKniIiIdC+XF9Jy7SVRwfrma1ObLKVNX9eWQaDKPj9Uby817XzUqMO1fzD1ZTQNs970hprk5vb3glkFEqHwKSIiIj2X2wfuPEjLS+w8M2x3EaivtNf+qobt+oqm79VXNl/7agbtPq7RLgXt5XC1Xuva5L30htrlxvt6UA2swqeIiIgcehzOhj6g7WFZdl/VfbsC1JU3CrMV9jq2VO6/bZl2gG1vt4Eow7lPN4FMe3vETJh8Wfs/txMofIqIiIgkyjAa5mjNaPtJS82KzirQpNa10p6btb6yIaQ2ea9xzWzkOCtsL80F2PaWrRMpfIqIiIh0h8azCiQyFVZj0RrYxsG0cYDtO6pjy9wBFD5FREREeqrGNbD07+7SxEUzsoqIiIhIl1H4FBEREZEuo/ApIiIiIl1G4VNEREREuozCp4iIiIh0GYVPEREREekyCp8iIiIi0mUUPkVERESkyyh8ioiIiEiXUfgUERERkS6j8CkiIiIiXUbhU0RERES6jMKniIiIiHQZhU8RERER6TIKnyIiIiLSZRQ+RURERKTLKHyKiIiISJdR+BQRERGRLqPwKSIiIiJdRuFTRERERLqMwqeIiIiIdBmFTxERERHpMgqfIiIiItJlFD5FREREpMsofIqIiIhIl1H4FBEREZEu067w+cADDzB06FB8Ph9Tp07lo48+avX4v//97xxxxBH4fD7GjRvHyy+/3K7CioiIiEjPlnD4fPbZZ5k/fz4LFy7k008/ZcKECcyaNYs9e/Y0e/z777/PhRdeyA9/+EM+++wzzjrrLM466yxWr159wIUXERERkZ4l4fB59913c8UVV3DZZZcxZswYFi1aRHJyMo8++mizx99777184xvf4P/9v//H6NGj+fWvf83RRx/N/ffff8CFFxEREZGexZXIwYFAgJUrV7JgwYLYPofDwYwZM1ixYkWz56xYsYL58+c32Tdr1ixefPHFFq/j9/vx+/2x1xUVFQCUlpYSDAYTKXK7BINBamtrKSkpwe12d/r1pPPoXvYeupe9h+5l76F72Xt0xL2sqqoCwLKsVo9LKHwWFxcTDofJzc1tsj83N5f169c3e05hYWGzxxcWFrZ4ndtvv51bb711v/3Dhg1LpLgiIiIi0sWqqqrIyMho8f2EwmdXWbBgQZPaUtM0KS0tpU+fPhiG0enXr6ysZNCgQezYsYP09PROv550Ht3L3kP3svfQvew9dC97j464l5ZlUVVVxYABA1o9LqHwmZOTg9PppKioqMn+oqIi8vLymj0nLy8voeMBvF4vXq+3yb7MzMxEitoh0tPT9cfUS+he9h66l72H7mXvoXvZexzovWytxjMqoQFHHo+HSZMmsWzZstg+0zRZtmwZ06ZNa/acadOmNTkeYOnSpS0eLyIiIiK9V8LN7vPnz+fSSy9l8uTJTJkyhXvuuYeamhouu+wyAC655BLy8/O5/fbbAbjmmms4+eSTueuuu/jmN7/JM888wyeffMJDDz3Usd9ERERERA56CYfP888/n71793LzzTdTWFjIUUcdxSuvvBIbVLR9+3YcjoYK1eOOO47Fixdz44038j//8z+MGDGCF198kbFjx3bct+hgXq+XhQsX7tf0Lz2P7mXvoXvZe+he9h66l71HV95Lw2prPLyIiIiISAfRs91FREREpMsofIqIiIhIl1H4FBEREZEuo/ApIiIiIl1G4XMfDzzwAEOHDsXn8zF16lQ++uij7i6SxOHtt99mzpw5DBgwAMMwePHFF5u8b1kWN998M/379ycpKYkZM2awcePG7imstOj222/nmGOOIS0tjX79+nHWWWdRUFDQ5Jj6+nquuuoq+vTpQ2pqKuecc85+D7KQ7venP/2J8ePHxyasnjZtGv/9739j7+s+9lx33HEHhmFw7bXXxvbpfvYMt9xyC4ZhNFmOOOKI2PtddR8VPht59tlnmT9/PgsXLuTTTz9lwoQJzJo1iz179nR30aQNNTU1TJgwgQceeKDZ93/3u9/xxz/+kUWLFvHhhx+SkpLCrFmzqK+v7+KSSmveeustrrrqKj744AOWLl1KMBjk9NNPp6amJnbMddddx7///W/+/ve/89Zbb7Fr1y7OPvvsbiy1NGfgwIHccccdrFy5kk8++YTTTjuNM888kzVr1gC6jz3Vxx9/zJ///GfGjx/fZL/uZ89x5JFHsnv37tjy7rvvxt7rsvtoScyUKVOsq666KvY6HA5bAwYMsG6//fZuLJUkCrBeeOGF2GvTNK28vDzr97//fWxfeXm55fV6raeffrobSijx2rNnjwVYb731lmVZ9n1zu93W3//+99gx69atswBrxYoV3VVMiVNWVpb1l7/8Rfexh6qqqrJGjBhhLV261Dr55JOta665xrIs/V32JAsXLrQmTJjQ7HtdeR9V8xkRCARYuXIlM2bMiO1zOBzMmDGDFStWdGPJ5EBt2bKFwsLCJvc2IyODqVOn6t4e5CoqKgDIzs4GYOXKlQSDwSb38ogjjmDw4MG6lwexcDjMM888Q01NDdOmTdN97KGuuuoqvvnNbza5b6C/y55m48aNDBgwgMMOO4y5c+eyfft2oGvvY8JPOOqtiouLCYfDsSc1ReXm5rJ+/fpuKpV0hMLCQoBm7230PTn4mKbJtddey/HHHx97IlphYSEej4fMzMwmx+peHpy+/PJLpk2bRn19PampqbzwwguMGTOGVatW6T72MM888wyffvopH3/88X7v6e+y55g6dSqPP/44o0aNYvfu3dx6662ceOKJrF69ukvvo8KniByUrrrqKlavXt2kP5L0LKNGjWLVqlVUVFTw/PPPc+mll/LWW291d7EkQTt27OCaa65h6dKl+Hy+7i6OHIAzzjgjtj1+/HimTp3KkCFDeO6550hKSuqycqjZPSInJwen07nfqK6ioiLy8vK6qVTSEaL3T/e255g3bx7/+c9/ePPNNxk4cGBsf15eHoFAgPLy8ibH614enDweD8OHD2fSpEncfvvtTJgwgXvvvVf3sYdZuXIle/bs4eijj8blcuFyuXjrrbf44x//iMvlIjc3V/ezh8rMzGTkyJFs2rSpS/8uFT4jPB4PkyZNYtmyZbF9pmmybNkypk2b1o0lkwM1bNgw8vLymtzbyspKPvzwQ93bg4xlWcybN48XXniBN954g2HDhjV5f9KkSbjd7ib3sqCggO3bt+te9gCmaeL3+3Ufe5jp06fz5ZdfsmrVqtgyefJk5s6dG9vW/eyZqqur2bx5M/379+/Sv0s1uzcyf/58Lr30UiZPnsyUKVO45557qKmp4bLLLuvuokkbqqur2bRpU+z1li1bWLVqFdnZ2QwePJhrr72W3/zmN4wYMYJhw4Zx0003MWDAAM4666zuK7Ts56qrrmLx4sX861//Ii0tLdbPKCMjg6SkJDIyMvjhD3/I/Pnzyc7OJj09nauvvppp06Zx7LHHdnPppbEFCxZwxhlnMHjwYKqqqli8eDHLly/n1Vdf1X3sYdLS0mL9rqNSUlLo06dPbL/uZ89w/fXXM2fOHIYMGcKuXbtYuHAhTqeTCy+8sGv/Ljt07HwvcN9991mDBw+2PB6PNWXKFOuDDz7o7iJJHN58800L2G+59NJLLcuyp1u66aabrNzcXMvr9VrTp0+3CgoKurfQsp/m7iFgPfbYY7Fj6urqrJ/+9KdWVlaWlZycbH3nO9+xdu/e3X2Flmb94Ac/sIYMGWJ5PB6rb9++1vTp063XXnst9r7uY8/WeKoly9L97CnOP/98q3///pbH47Hy8/Ot888/39q0aVPs/a66j4ZlWVbHxlkRERERkeapz6eIiIiIdBmFTxERERHpMgqfIiIiItJlFD5FREREpMsofIqIiIhIl1H4FBEREZEuo/ApIiIiIl1G4VNEREREuozCp4iIiIh0GYVPEREREekyCp8iIiIi0mUUPkVERESky/x/YTwjAALNqYAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9685 - loss: 0.1087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0917351022362709, 0.9729999899864197]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.1527222e-05, 6.3627169e-07, 2.1027935e-04, 3.2419292e-03,\n",
       "        8.9753405e-09, 1.0588444e-04, 4.8433431e-11, 9.9636817e-01,\n",
       "        7.0547735e-06, 5.4552122e-05]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99636817"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 966,    0,    1,    2,    1,    3,    3,    3,    1,    0],\n",
       "       [   0, 1121,    3,    1,    0,    1,    4,    1,    4,    0],\n",
       "       [   3,    1, 1007,    5,    3,    0,    3,    6,    4,    0],\n",
       "       [   0,    0,    4,  990,    1,    5,    0,    3,    4,    3],\n",
       "       [   1,    0,    3,    0,  951,    0,    6,    2,    2,   17],\n",
       "       [   3,    0,    0,    5,    1,  872,    7,    0,    2,    2],\n",
       "       [   5,    3,    0,    1,    5,   10,  931,    0,    3,    0],\n",
       "       [   0,    9,   10,    7,    0,    1,    0,  993,    1,    7],\n",
       "       [   4,    0,    6,   13,    3,    7,    2,    2,  935,    2],\n",
       "       [   5,    6,    1,   11,   10,    5,    1,    6,    0,  964]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\OneDrive\\code_dgerwig\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.2494 - val_loss: 0.5887\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5220 - val_loss: 0.5143\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4744 - val_loss: 0.4717\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4272 - val_loss: 0.4471\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4376 - val_loss: 0.4353\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4072 - val_loss: 0.6419\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4675 - val_loss: 0.4530\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3900 - val_loss: 0.4282\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3974 - val_loss: 0.4104\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3807 - val_loss: 0.4091\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3781 - val_loss: 0.4004\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3904 - val_loss: 0.3996\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3659 - val_loss: 0.3973\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3639 - val_loss: 0.3973\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3684 - val_loss: 0.3925\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3542 - val_loss: 0.4047\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3726 - val_loss: 0.4030\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3529 - val_loss: 0.3936\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3474 - val_loss: 0.3884\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3665 - val_loss: 0.3897\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3348\n",
      "0.35995417833328247\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.1051416],\n",
       "       [1.8014948],\n",
       "       [1.7512326],\n",
       "       [3.9526715],\n",
       "       [1.4803748]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3616\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3535\n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3660\n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3572\n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3415\n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3651\n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3640\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3777\n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3591\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3406\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 0.3562\n",
      "Epoch 12/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3441\n",
      "Epoch 13/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3475\n",
      "Epoch 14/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.3704\n",
      "Epoch 15/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.3447\n",
      "Epoch 16/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3498  \n",
      "Epoch 17/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3438\n",
      "Epoch 18/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.3421\n",
      "Epoch 19/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3468\n",
      "Epoch 20/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3354\n",
      "Epoch 21/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3268\n",
      "Epoch 22/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3535\n",
      "Epoch 23/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.3265\n",
      "Epoch 24/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3504  \n",
      "Epoch 25/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3509\n",
      "Epoch 26/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3444  \n",
      "Epoch 27/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3329\n",
      "Epoch 28/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - loss: 0.3252\n",
      "Epoch 29/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.3411\n",
      "Epoch 30/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - loss: 0.3375\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3333 - val_loss: 0.3570\n",
      "Epoch 2/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3369 - val_loss: 0.3578\n",
      "Epoch 3/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3243 - val_loss: 0.3599\n",
      "Epoch 4/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3210 - val_loss: 0.3568\n",
      "Epoch 5/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3332 - val_loss: 0.3636\n",
      "Epoch 6/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3356 - val_loss: 0.3587\n",
      "Epoch 7/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3406 - val_loss: 0.3556\n",
      "Epoch 8/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3436 - val_loss: 0.3561\n",
      "Epoch 9/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3273 - val_loss: 0.3589\n",
      "Epoch 10/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3279 - val_loss: 0.3552\n",
      "Epoch 11/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3314 - val_loss: 0.3568\n",
      "Epoch 12/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3286 - val_loss: 0.3537\n",
      "Epoch 13/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3094 - val_loss: 0.3507\n",
      "Epoch 14/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3237 - val_loss: 0.3592\n",
      "Epoch 15/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3142 - val_loss: 0.3500\n",
      "Epoch 16/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3181 - val_loss: 0.3709\n",
      "Epoch 17/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3120 - val_loss: 0.3531\n",
      "Epoch 18/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3222 - val_loss: 0.3477\n",
      "Epoch 19/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3350 - val_loss: 0.3483\n",
      "Epoch 20/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3153 - val_loss: 0.4569\n",
      "Epoch 21/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3291 - val_loss: 0.3451\n",
      "Epoch 22/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3133 - val_loss: 0.3816\n",
      "Epoch 23/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4201 - val_loss: 0.3458\n",
      "Epoch 24/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3331 - val_loss: 0.3479\n",
      "Epoch 25/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3203 - val_loss: 0.3432\n",
      "Epoch 26/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3018 - val_loss: 0.3543\n",
      "Epoch 27/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3080 - val_loss: 0.3503\n",
      "Epoch 28/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3163 - val_loss: 0.3453\n",
      "Epoch 29/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3093 - val_loss: 0.3473\n",
      "Epoch 30/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3218 - val_loss: 0.3469\n",
      "Epoch 31/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3089 - val_loss: 0.3483\n",
      "Epoch 32/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3078 - val_loss: 0.4887\n",
      "Epoch 33/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3067 - val_loss: 0.3463\n",
      "Epoch 34/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3149 - val_loss: 0.3455\n",
      "Epoch 35/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3095 - val_loss: 0.3446\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
