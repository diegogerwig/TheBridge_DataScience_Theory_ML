{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7SN5USFEIIK3"
   },
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6mJg1g3apaz"
   },
   "source": [
    "Este tutorial contiene una introducción a las embeddings de palabras. Entrenaréis vuestros propios embeddings de palabras utilizando un modelo simple de Keras para una tarea de clasificación de sentimiento, y luego podrá ser visualizados los resultados en el [Proyector de Embeddings](http://projector.tensorflow.org).\n",
    "\n",
    "## Representación del texto como números\n",
    "\n",
    "Los modelos de aprendizaje automático toman vectores (matrices de números) como entrada. Cuando se trabaja con texto, lo primero que hay que hacer es idear una estrategia para convertir las cadenas en números (o «vectorizar» el texto) antes de introducirlo en el modelo. En esta sección, veremos tres estrategias para hacerlo.\n",
    "\n",
    "### 1. Codificaciones de una sola vez\n",
    "\n",
    "Una de las aproximaciones más simples es codificar «una sola vez» cada palabra de su vocabulario. Piensa en la frase «El gato se sentó en la alfombra». El vocabulario (o las palabras únicas) de esta frase es (gato, colchoneta, sobre, se sentó, el). Para representar cada palabra, se crea un vector cero con una longitud igual a la del vocabulario y, a continuación, se coloca un uno en el índice correspondiente a la palabra.\n",
    "\n",
    "Para crear un vector que contenga la codificación de la frase, se trata unicamente de concatenar los 1s.\n",
    "\n",
    "**Punto clave**: Un vector codificado con una sola palabra es disperso (es decir, la mayoría de los índices son cero). Imagina que tienes 10.000 palabras en el vocabulario. Para codificar cada palabra de una sola vez, tendría que crear un vector en el que el 99,99% de los elementos fueran cero\n",
    "\n",
    "### 2. Codificar cada palabra con un número único\n",
    "\n",
    "Una segunda posibilidad es codificar cada palabra con un **número único**. Continuando con el ejemplo anterior, podrías asignar 1 a «gato», 2 a «alfombrilla», y así sucesivamente. Así, podrías codificar la frase «El gato se sentó en la alfombra» como un vector denso del tipo [5, 1, 4, 3, 5, 2]. Este método es eficaz. En lugar de un vector disperso, ahora tenemos uno denso (en el que todos los elementos están llenos).\n",
    "\n",
    "Sin embargo, este método tiene dos inconvenientes:\n",
    "\n",
    "* La codificación entera es arbitraria (no captura ninguna relación entre palabras).\n",
    "\n",
    "* Una codificación entera puede ser difícil de interpretar para un modelo. Un clasificador lineal, por ejemplo, aprende un único peso para cada característica. Dado que no existe ninguna relación entre la similitud de dos palabras y la similitud de sus codificaciones, esta combinación de características y pesos no tiene sentido.\n",
    "\n",
    "### 3. Word embeddings\n",
    "\n",
    "Los embeddings de palabras nos permiten utilizar **una representación densa y eficaz** en la que palabras similares tienen una codificación similar. Y lo que es más importante, no es necesario especificar esta codificación a mano. Un embedding es un vector denso de valores de coma flotante (la longitud del vector es un parámetro que usted especifica). En lugar de especificar manualmente los valores del embedding, se trata de parámetros entrenables (pesos aprendidos por el modelo durante el entrenamiento, del mismo modo que un modelo aprende pesos para una capa densa). Es habitual ver embeddings de palabras de 8 dimensiones (para conjuntos de datos pequeños), hasta 1024 dimensiones cuando se trabaja con conjuntos de datos grandes. Un embedding de mayor dimensión puede captar relaciones más precisas entre las palabras, pero requiere más datos para su aprendizaje.\n",
    "\n",
    "![embedding](img/mbedding.webp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SZUQErGewZxE"
   },
   "source": [
    "## Configuración\n",
    "\n",
    "Usaremos Keras para trabajar con nuestros vectores de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RutaI-Tpev3T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 09:14:13.367544: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-24 09:14:13.376326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-24 09:14:13.385828: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-24 09:14:13.388605: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-24 09:14:13.396364: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 09:14:13.928701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SBFctV8-JZOc"
   },
   "source": [
    "### Descargar el conjunto de datos IMDb\n",
    "Durante el tutorial se utilizará el [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/). Entrenarás un modelo clasificador de sentimiento en este conjunto de datos y en el proceso aprenderás incrustaciones desde cero.\n",
    "\n",
    "Echa un vistazo al directorio `train/`. Tiene las carpetas `pos` y `neg` con críticas de películas etiquetadas como positivas y negativas respectivamente. Utilizarás las críticas de las carpetas `pos` y `neg` para entrenar un modelo de clasificación binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9-iOHJGN6SDu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/iraitz/TheBridge/Otros/TheBridge_DSPT_ML/Lenguaje Natural/3-Embeddings/aclImdb/train'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), \"aclImdb\", \"train\")\n",
    "dataset_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oFoJjiEyJz9u"
   },
   "source": [
    "A continuación, crea un `tf.data.Dataset` usando `tf.keras.preprocessing.text_dataset_from_directory`. Puedes leer más sobre el uso de esta utilidad en este [tutorial de clasificación de texto](https://www.tensorflow.org/tutorials/keras/text_classification). \n",
    "\n",
    "Utilice el directorio `train` para crear conjuntos de datos de entrenamiento y validación con una división del 20% para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ItYD3TLkCOP1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 60000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721805257.941399  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805257.962479  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805257.962626  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805257.963756  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805257.963860  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805257.963921  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805258.020937  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805258.021055  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805258.021133  173887 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-24 09:14:18.021203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6297 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 15000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'training',\n",
    "    seed = seed\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'validation',\n",
    "    seed = seed\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eHa6cq0-Ym0g"
   },
   "source": [
    "Observa algunas críticas de películas y sus etiquetas `(1: positivo, 0: negativo)` del conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aTCbSkvkYmTT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 b\"Ask yourself where she got the gun? Remember what she was taught about the mark's mindset when the con is over? The gun had blanks and it was provided to her from the very beginning.<br /><br />When the patient comes back at the end she was SUPPOSED to see him drive away in the red convertible and lead her to the gang splitting up her 80 thousand.<br /><br />The patient was in on the con from the beginning.<br /><br />Mantegna does not die in the end - the gun had blanks.<br /><br />There - enough spoilers for you there? This is why people are giving it such high ratings. It's extremely original because of the hidden ending and how it cons MOST of the audience.\"\n",
      "2 b\"For some reason, people seem to have a problem differentiating this movie from Trail of the Pink Panther.<br /><br />At any rate, this work does nothing but serve to remind us how sad the world is without Peter Sellers in it.<br /><br />They brought back the same old favorites from Trail (Dreyfus, Cato, Litton, etc.), but they introduced a misdirected Pratt-fall humorist into a role which was designed to substitute for the missing Clouseau. <br /><br />Dreyfus devises a way to produce the perfect copy of Clouseau via a hard frame computer system which factors the variables and tosses out the name of the most inept idiot in the global law enforcement family. What we got was a poor guy who was obviously overwhelmed by the grand scale of what Blake Edwards proposed he should do, and boy does it show.<br /><br />Ted Wass was amiable as Sergeant Clifton Sleigh, but let's face it...he wasn't Clouseau in any way. I realize that Blake Edwards was losing his greatest cash cow, but to disrespect Sellers' memory like this was just sacrilege. Frankly, I'm glad they have remade the original. I hope it runs a long line of successful ventures for Steve Martin.<br /><br />This dreck rates a 2.0/10 from...<br /><br />the Fiend :.\"\n",
      "2 b\"Jimeoin is a nameless actor who finds himself as the eternal extra\\xc2\\x85 never to play a principle role in a movie. He finds himself caught up with a group of would-be stars all trying to gain a break but none of them are able to do so.<br /><br />I was ready for a good comedy, but was bitterly disappointed. Jimeoin is a great comedian but this smacked of 'try hard' and it just failed. There were a few moments where I laughed out aloud and I recognised several moments of clever humour, but it wasn't enough. I enjoyed spotting the good familiar Aussie actors and scenes around Melbourne. I think you should spend your money seeing something else...\"\n",
      "2 b'\"And I\\'ve had vould have gotten avay vith it, too, if it veren\\'t for you meddling Ritzes! Blah, blah!\" <br /><br />No, not really. Poor Bela was continuing his spiraling descent from the triumph of Dracula to working for Ed Wood. He actually has a half comedic, half heroic role in this movie, but mostly he spends the movie being a distraction from what could laughably be called a plot.<br /><br />One has to wonder if the Scooby-Doo cartoons were inspired by movies like this. YOu had everything you see in your average Scooby cartoon- secret passages, some guy in a costume, ulterior motives (which, unlike a Scooby cartoon, don\\'t actually make sense here.) <br /><br />Okay, the Ritz Brothers. They were a very popular vaudeville act back in the day, but no one remembers them much today. Watching this film, you can see why. They didn\\'t have the comic timing, distinct personalities or perfect slapstick of the Three Stooges or Marx Brothers. They were pretty much interchangeable, with Jimmy and Al mugging while Harry got most of the dialog.<br /><br />There is a bit of interesting Hollywood history that the Ritzes staged a \"walkout\" on this film, to protest the quality of the script. 20th Century Fox should have let them walk and reworked the script. Instead, they finished the movie, and Fox kicked them to the curb.<br /><br />I don\\'t understand the plot. I guess that Atwill was supposed to be the villain, but really the guy who was pretending to be SEC agent was the actual killer, but it was never clear why he was killing people or why he would walk into the trap that Atwill and Lugosi had set for him. The ending makes absolutely no sense.<br /><br />You almost get the impression that there were a lot of b-listers (The Ritzes, Lugosi, Atwill, Patsy Kelly) who were insisting that THEY get more screen time than the others. Other characters, like the \"seaman\" who is found in the closet, are introduced and no explanation is given as to what they were doing there.'\n",
      "1 b'I think if you were to ask most JW\\'s whether they expect a miracle cure because of their faith, you will find they do not. I know I do not. What you will find instead is that they believe the promises Christ made of a resurrection. So, even even if the worst were to happen and we die while holding onto our integrity, Jehovah can, and will correct this.<br /><br />It really gets down to a simple question: is God real to you or is this all just make believe? If he is real, and you trust him, you will follow his directions no matter what the short term outcome may be.<br /><br />I had a heart attack about a year and a half ago. One in my family was horrified when she saw the words \"NO BLOOD\" written in large letters over my chart. I reasoned with her that if I were in a position that only a blood transfusion would save my life, would that be a good time to anger the only one could return me to life when the time came? She didn\\'t get it -- God just isn\\'t real enough to her. Too bad. I wish she could have the comfort a strong faith gives.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 09:14:19.657944: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(5): \n",
    "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eqBazMiVQkj1"
   },
   "source": [
    "## Usando la capa Embedding\n",
    "\n",
    "Keras facilita el uso de incrustaciones de palabras. Echa un vistazo a la capa [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding).\n",
    "\n",
    "La capa Embedding puede ser entendida como una tabla de búsqueda que mapea desde índices enteros (que representan palabras específicas) a vectores densos (sus incrustaciones). La dimensionalidad (o anchura) de la incrustación es un parámetro con el que puede experimentar para ver qué funciona bien para su problema, del mismo modo que experimentaría con el número de neuronas en una capa densa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-OjxLVrMvWUE"
   },
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2dKKV1L2Rk7e"
   },
   "source": [
    "Cuando se crea una capa de embedding, los pesos del embedding se inicializan aleatoriamente (como cualquier otra capa). Durante el entrenamiento, se ajustan gradualmente mediante retropropagación. Una vez entrenadas, las incrustaciones de palabras aprendidas codificarán aproximadamente las similitudes entre palabras (ya que fueron aprendidas para el problema específico en el que se entrena el modelo).\n",
    "\n",
    "Si pasa un número entero a una capa de embedding, el resultado sustituye cada número entero por el vector de la tabla de embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0YUjPgP7w0PO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04623629, -0.04370539,  0.03233461, -0.00733647, -0.036759  ],\n",
       "       [ 0.00241052, -0.02127037, -0.01343727,  0.03349702,  0.01657147],\n",
       "       [ 0.01297109,  0.00483005,  0.0022527 ,  0.03880982,  0.01060029],\n",
       "       [-0.04881912, -0.01761485, -0.03210603,  0.00977444,  0.01555166],\n",
       "       [-0.0046904 , -0.03185989, -0.04879421, -0.02360058,  0.03896526],\n",
       "       [ 0.02033808,  0.02909926,  0.03333262,  0.03596048,  0.01132948]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([0,1,2,3,4,999]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasVariable shape=(1000, 5), dtype=float32, path=embedding/embeddings>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding_layer.embeddings.shape)\n",
    "embedding_layer.embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "O4PC4QzsxTGx"
   },
   "source": [
    "Para problemas de texto o secuencias, la capa de embedding toma un tensor 2D de enteros, de forma `(muestras, longitud_secuencia)`, donde cada entrada es una secuencia de enteros. Puede incrustar secuencias de longitudes variables. Podría introducir en la capa de embedding anterior lotes con formas `(32, 10)` (lote de 32 secuencias de longitud 10) o `(64, 15)` (lote de 64 secuencias de longitud 15).\n",
    "\n",
    "El tensor devuelto tiene un eje más que el de entrada, los vectores de embedding se alinean a lo largo del nuevo último eje. Pásele un lote de entrada `(2, 3)` y la salida será `(2, 3, N)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vwSYepRjyRGy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00241052, -0.02127037, -0.01343727,  0.03349702,\n",
       "          0.01657147],\n",
       "        [ 0.01297109,  0.00483005,  0.0022527 ,  0.03880982,\n",
       "          0.01060029],\n",
       "        [ 0.02033808,  0.02909926,  0.03333262,  0.03596048,\n",
       "          0.01132948]],\n",
       "\n",
       "       [[-0.04881912, -0.01761485, -0.03210603,  0.00977444,\n",
       "          0.01555166],\n",
       "        [-0.0046904 , -0.03185989, -0.04879421, -0.02360058,\n",
       "          0.03896526],\n",
       "        [ 0.04388979,  0.03584692,  0.04688055,  0.03256333,\n",
       "         -0.01453091]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([[1, 2, 999],\n",
    "                                      [3, 4, 5]]))\n",
    "print(result.shape)\n",
    "result.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WGQp2N92yOyB"
   },
   "source": [
    "Cuando se le da un lote de secuencias como entrada, una capa de embedding devuelve un tensor 3D de coma flotante, de forma `(muestras, longitud_de_secuencia, dimensionalidad_de_embedding)`. Para convertir de esta secuencia de longitud variable a una representación fija hay una variedad de enfoques estándar. Se puede utilizar una capa RNN, Attention o pooling antes de pasarla a una capa Dense. Este tutorial utiliza pooling porque es el más sencillo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aGicgV5qT0wh"
   },
   "source": [
    "## Procesado de texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "N6NZSqIIoU0Y"
   },
   "source": [
    "A continuación, definiremos los pasos de preprocesamiento del conjunto de datos necesarios para su modelo de clasificación de sentimientos. Inicialice una capa TextVectorization con los parámetros deseados para vectorizar las críticas de películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2MlsXzo-ZlfK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 09:14:28.898866: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize = custom_standardization,\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = sequence_length\n",
    ")\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zI9_wLIiWO8Z"
   },
   "source": [
    "## Crear un modelo de clasificación\n",
    "\n",
    "Utilizaremos la [Keras Sequential API](https://www.tensorflow.org/guide/keras/sequential_model) para definir el modelo de clasificación de sentimiento. En este caso es un modelo del estilo «Continuous bag of words».\n",
    "* La capa [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) transforma cadenas en índices de vocabulario. Ya has inicializado `vectorize_layer` como una capa de TextVectorization y construido su vocabulario llamando a `adapt` en `text_ds`. Ahora vectorize_layer se puede utilizar como la primera capa de su modelo de clasificación de extremo a extremo, la alimentación de cadenas transformadas en la capa de incrustación.\n",
    "* La capa [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) toma el vocabulario codificado con enteros y busca el vector de incrustación para cada índice de palabra. Estos vectores se aprenden a medida que el modelo se entrena. Los vectores añaden una dimensión a la matriz de salida. Las dimensiones resultantes son: `(lote, secuencia, incrustación)`.\n",
    "\n",
    "* La capa [`GlobalAveragePooling1D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D) devuelve un vector de salida de longitud fija para cada ejemplo promediando sobre la dimensión de secuencia. Esto permite al modelo manejar entradas de longitud variable de la forma más sencilla posible.\n",
    "\n",
    "* El vector de salida de longitud fija se canaliza a través de una capa totalmente conectada ([`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) con 16 unidades ocultas.\n",
    "\n",
    "* La última capa está densamente conectada con un único nodo de salida. \n",
    "\n",
    "Atención: Este modelo no utiliza enmascaramiento, por lo que el relleno cero se utiliza como parte de la entrada y, por tanto, la longitud del relleno puede afectar a la salida.  Para solucionarlo, consulta la [guía de enmascaramiento y relleno](https://www.tensorflow.org/guide/keras/masking_and_padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pHLcFtn5Wsqj"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "vocab_size = 10000\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, name='embedding'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JjLNgKO7W2fe"
   },
   "source": [
    "## Compilamos y entrenamos el modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jpX9etB6IOQd"
   },
   "source": [
    "Utilizarás [TensorBoard](https://www.tensorflow.org/tensorboard) para visualizar métricas incluyendo pérdida y precisión. Crearemos un `tf.keras.callbacks.TensorBoard`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "W4Hg3IHFt4Px"
   },
   "outputs": [],
   "source": [
    "tbcallback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=0,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7OrKAKAKIbuH"
   },
   "source": [
    "Compila y entrena usando el optimizador `Adam` y la pérdida `BinaryCrossentropy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lCUgdP69Wzix"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1695 - loss: -21891.4609 - val_accuracy: 0.1690 - val_loss: -23107.2734\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1692 - loss: -23934.3145 - val_accuracy: 0.1690 - val_loss: -25161.6426\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1689 - loss: -25925.4883 - val_accuracy: 0.1690 - val_loss: -27315.2090\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1681 - loss: -28450.2324 - val_accuracy: 0.1690 - val_loss: -29577.2695\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1675 - loss: -30538.3145 - val_accuracy: 0.1690 - val_loss: -31934.5352\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1672 - loss: -33275.8516 - val_accuracy: 0.1690 - val_loss: -34406.0898\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1692 - loss: -35498.2461 - val_accuracy: 0.1690 - val_loss: -36981.7930\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1682 - loss: -38192.1016 - val_accuracy: 0.1690 - val_loss: -39667.2656\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1688 - loss: -40823.2422 - val_accuracy: 0.1690 - val_loss: -42455.4648\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1680 - loss: -43659.1680 - val_accuracy: 0.1690 - val_loss: -45363.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77347df57b90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 10,\n",
    "    callbacks=[tbcallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-24 09:15:06.681335: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-24 09:15:06.689904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-24 09:15:06.699444: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-24 09:15:06.702257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-24 09:15:06.709865: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 09:15:07.146059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721805307.704120  174761 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805307.725529  174761 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721805307.725682  174761 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1wYnVedSPfmX"
   },
   "source": [
    "Se ve que en nuestro caso el resultado no es muy bueno, toca jugar con la arquitectura para ver mejores resultados.\n",
    "\n",
    "Puede consultar el resumen del modelo para obtener más información sobre cada capa del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mDCgjWyq_0dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │       \u001b[38;5;34m160,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480,869</span> (1.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m480,869\u001b[0m (1.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,289</span> (626.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m160,289\u001b[0m (626.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,580</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m320,580\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KCoA6qwqP836"
   },
   "source": [
    "## Recupera los embeddings de palabras entrenadas y guardalas\n",
    "\n",
    "A continuación, recupere los embeddings de palabras aprendidas durante el entrenamiento. Los embeddings son pesos de la capa Embedding en el modelo. La matriz de pesos tiene la forma `(vocab_size, embedding_dimension)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-144.44925   , -142.90196   ,  145.35532   , ..., -144.58495   ,\n",
       "          143.64536   , -140.99751   ],\n",
       "        [-175.28365   , -173.52979   ,  175.6521    , ..., -175.8469    ,\n",
       "          174.50255   , -171.24246   ],\n",
       "        [-166.29767   , -164.64468   ,  166.68562   , ..., -166.78928   ,\n",
       "          165.55664   , -162.46303   ],\n",
       "        ...,\n",
       "        [  -1.4809538 ,   -1.4849576 ,    1.5274029 , ...,   -1.5311236 ,\n",
       "            1.527871  ,   -1.4855096 ],\n",
       "        [  -1.3023555 ,   -1.2495835 ,    1.2694421 , ...,   -1.317147  ,\n",
       "            1.3137275 ,   -1.2370903 ],\n",
       "        [  -0.6727082 ,   -0.61914897,    0.66247225, ...,   -0.61728567,\n",
       "            0.63086647,   -0.6857476 ]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('embedding').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_Uamp1YH8RzU"
   },
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n",
      "[[-144.44925 -142.90196  145.35532  142.65868  142.36775 -142.2914\n",
      "   142.062   -144.477    144.83801 -143.59645 -143.00455 -146.32506\n",
      "  -143.02974 -144.58495  143.64536 -140.99751]\n",
      " [-175.28365 -173.52979  175.6521   173.12965  172.70372 -172.84514\n",
      "   172.24977 -175.66295  175.90012 -174.243   -173.44789 -177.46103\n",
      "  -173.57501 -175.8469   174.50255 -171.24246]]\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "print(weights[:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "J8MiCA77X8B8"
   },
   "source": [
    "Guardaremos los resultados para poder emplearlos como fuente en el [Embedding Projector](http://projector.tensorflow.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VLIahl9s53XT"
   },
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXLfFA54Yz-o"
   },
   "source": [
    "## Visualiza los Embeddings\n",
    "\n",
    "Para visualizar los embeddings, cárgalos en el proyector de embeddings.\n",
    "\n",
    "Abrir el [Proyector integrado](http://projector.tensorflow.org/) (esto también se puede ejecutar en una instancia local de TensorBoard).\n",
    "\n",
    "* Haz clic en \"Cargar datos\".\n",
    "\n",
    "* Sube los dos archivos que creaste anteriormente: `vecs.tsv` y `meta.tsv`.\n",
    "\n",
    "Ahora se mostrarán los embeddings que ha entrenado. Puedes buscar palabras para encontrar sus vecinos más cercanos. Por ejemplo, intenta buscar \"hermosa\". Es posible que vea vecinos como \"maravillosos\".\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wvKiEHjramNh"
   },
   "source": [
    "## Tutoriales de ayuda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BSgAZpwF5xF_"
   },
   "source": [
    "Este tutorial te ha mostrado cómo entrenar y visualizar embeddings de palabras desde cero en un pequeño conjunto de datos.\n",
    "\n",
    "* Para entrenar embeddings de palabras usando el algoritmo Word2Vec, prueba el tutorial [Word2Vec](https://www.tensorflow.org/tutorials/text/word2vec).\n",
    "\n",
    "* Para obtener más información sobre el procesamiento de texto avanzado, lee el [Modelo Transformer para la comprensión del lenguaje](https://www.tensorflow.org/tutorials/text/transformer).\n",
    "\n",
    "* Echad un ojo a [Llama Index](https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word_embeddings.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
